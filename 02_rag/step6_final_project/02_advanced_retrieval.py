#!/usr/bin/env python3
"""
RAGæœ€ç»ˆé¡¹ç›® - é«˜çº§æ£€ç´¢ç­–ç•¥

åŠŸèƒ½ï¼š
1. æ··åˆæ£€ç´¢ï¼ˆå‘é‡ + å…³é”®è¯ï¼‰
2. ç»“æœé‡æ’åºï¼ˆRerankingï¼‰
3. ä¸Šä¸‹æ–‡çª—å£ä¼˜åŒ–
4. æ€§èƒ½å¯¹æ¯”

è¿™æ˜¯æå‡RAGå‡†ç¡®ç‡çš„å…³é”®æŠ€æœ¯
"""

import os
import time
import chromadb
from sentence_transformers import SentenceTransformer
from typing import List, Dict, Any, Tuple


class AdvancedRetriever:
    """é«˜çº§æ£€ç´¢å™¨ï¼šå®ç°å¤šç§æ£€ç´¢ç­–ç•¥"""
    
    def __init__(self, 
                 chroma_path: str = "./data/document_store",
                 collection_name: str = "documents"):
        """åˆå§‹åŒ–æ£€ç´¢å™¨"""
        print("ğŸ“¦ åŠ è½½å‘é‡æ¨¡å‹...")
        self.embedding_model = SentenceTransformer('shibing624/text2vec-base-chinese')
        # è®¾ç½®å½’ä¸€åŒ–ï¼šè¾“å‡ºçš„å‘é‡è‡ªåŠ¨L2å½’ä¸€åŒ–åˆ°å•ä½é•¿åº¦
        self.embedding_model.encode_kwargs = {'normalize_embeddings': True}
        
        print(f"ğŸ’¾ è¿æ¥æ–‡æ¡£åº“...")
        self.client = chromadb.PersistentClient(path=chroma_path)
        
        try:
            self.collection = self.client.get_collection(name=collection_name)
            print(f"âœ… æ£€ç´¢å™¨åˆå§‹åŒ–å®Œæˆï¼æ–‡æ¡£å—æ•°ï¼š{self.collection.count()}\n")
        except:
            print(f"âŒ æ–‡æ¡£åº“ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ 01_document_manager.py")
            raise
    
    def vector_search(self, 
                     query: str, 
                     n_results: int = 10) -> List[Dict[str, Any]]:
        """
        çº¯å‘é‡æ£€ç´¢ï¼ˆåŸºç¡€æ–¹æ³•ï¼‰
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            n_results: è¿”å›ç»“æœæ•°
            
        Returns:
            æ£€ç´¢ç»“æœåˆ—è¡¨
        """
        start_time = time.time()
        
        # ç”ŸæˆæŸ¥è¯¢å‘é‡ï¼ˆå·²å½’ä¸€åŒ–ï¼‰
        query_embedding = self.embedding_model.encode(
            query,
            convert_to_numpy=True,
            normalize_embeddings=True
        )
        
        # å‘é‡æ£€ç´¢
        results = self.collection.query(
            query_embeddings=[query_embedding.tolist()],
            n_results=n_results
        )
        
        # æ ¼å¼åŒ–ç»“æœ
        formatted_results = []
        for i in range(len(results['ids'][0])):
            distance = results['distances'][0][i]
            
            # å…³é”®ä¿®æ­£ï¼šå½’ä¸€åŒ–å‘é‡çš„L2è·ç¦» è½¬ ä½™å¼¦ç›¸ä¼¼åº¦
            # å¯¹äºå½’ä¸€åŒ–å‘é‡: cosine_similarity = 1 - (L2_distance^2 / 2)
            # ç®€åŒ–ï¼šå½“å‘é‡å·²å½’ä¸€åŒ–ï¼ŒL2è·ç¦»å¾ˆå°æ—¶ï¼Œcos_sim â‰ˆ 1 - distance/2
            # ä½†ChromaDBè¿”å›çš„æ˜¯å¹³æ–¹è·ç¦»ï¼Œæ‰€ä»¥ï¼š
            import math
            # å¦‚æœdistanceæ˜¯L2è·ç¦»çš„å¹³æ–¹ï¼Œåˆ™ï¼šcos_sim = 1 - distance/2
            # å¦‚æœdistanceæ˜¯L2è·ç¦»ï¼Œåˆ™ï¼šcos_sim = 1 - distance^2/2
            
            # ä¿å®ˆå¤„ç†ï¼šå°†è·ç¦»æ˜ å°„åˆ°[0,1]
            # å¯¹äºå½’ä¸€åŒ–å‘é‡ï¼ŒL2è·ç¦»èŒƒå›´æ˜¯[0, 2]ï¼ˆæœ€å¤§æ˜¯åå‘ï¼‰
            # ç›¸ä¼¼åº¦ = (2 - distance) / 2 = 1 - distance/2
            similarity = max(0, min(1, 1 - distance / 2))
            
            formatted_results.append({
                'id': results['ids'][0][i],
                'document': results['documents'][0][i],
                'distance': distance,
                'similarity': similarity,
                'metadata': results['metadatas'][0][i],
                'method': 'vector_only'
            })
        
        elapsed = time.time() - start_time
        return formatted_results, elapsed
    
    def keyword_search(self, 
                       query: str, 
                       n_results: int = 10) -> List[Dict[str, Any]]:
        """
        å…³é”®è¯æ£€ç´¢ï¼ˆåŸºäºæ–‡æœ¬åŒ¹é…ï¼‰
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            n_results: è¿”å›ç»“æœæ•°
            
        Returns:
            æ£€ç´¢ç»“æœåˆ—è¡¨
        """
        start_time = time.time()
        
        # è·å–æ‰€æœ‰æ–‡æ¡£
        all_docs = self.collection.get()
        
        # è®¡ç®—å…³é”®è¯åŒ¹é…åˆ†æ•°
        results_with_score = []
        query_lower = query.lower()
        query_chars = set(query)
        
        for i, doc in enumerate(all_docs['documents']):
            doc_lower = doc.lower()
            
            # è®¡ç®—åŒ¹é…åˆ†æ•°
            score = 0
            
            # 1. å®Œå…¨åŒ¹é…ï¼ˆæœ€é«˜åˆ†ï¼‰
            if query in doc:
                score += 100
            
            # 2. åŒ…å«æ‰€æœ‰æŸ¥è¯¢å­—ç¬¦
            doc_chars = set(doc)
            char_overlap = len(query_chars & doc_chars) / len(query_chars)
            score += char_overlap * 50
            
            # 3. æŸ¥è¯¢è¯å‡ºç°æ¬¡æ•°
            for char in query:
                score += doc.count(char) * 2
            
            if score > 0:
                results_with_score.append({
                    'id': all_docs['ids'][i],
                    'document': doc,
                    'score': score,
                    'similarity': min(score / 100, 1.0),  # å½’ä¸€åŒ–åˆ°0-1
                    'metadata': all_docs['metadatas'][i],
                    'method': 'keyword_only'
                })
        
        # æŒ‰åˆ†æ•°æ’åº
        results_with_score.sort(key=lambda x: x['score'], reverse=True)
        
        elapsed = time.time() - start_time
        return results_with_score[:n_results], elapsed
    
    def hybrid_search(self, 
                     query: str, 
                     n_results: int = 10,
                     vector_weight: float = 0.7,
                     keyword_weight: float = 0.3) -> List[Dict[str, Any]]:
        """
        æ··åˆæ£€ç´¢ï¼ˆå‘é‡ + å…³é”®è¯ï¼‰
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            n_results: è¿”å›ç»“æœæ•°
            vector_weight: å‘é‡æ£€ç´¢æƒé‡
            keyword_weight: å…³é”®è¯æ£€ç´¢æƒé‡
            
        Returns:
            æ£€ç´¢ç»“æœåˆ—è¡¨
        """
        start_time = time.time()
        
        # 1. åˆ†åˆ«æ‰§è¡Œä¸¤ç§æ£€ç´¢
        vector_results, _ = self.vector_search(query, n_results=20)
        keyword_results, _ = self.keyword_search(query, n_results=20)
        
        # 2. åˆå¹¶ç»“æœ
        all_results = {}
        
        # æ·»åŠ å‘é‡æ£€ç´¢ç»“æœ
        for result in vector_results:
            doc_id = result['id']
            all_results[doc_id] = {
                'id': doc_id,
                'document': result['document'],
                'metadata': result['metadata'],
                'vector_score': result['similarity'],
                'keyword_score': 0,
                'method': 'hybrid'
            }
        
        # æ·»åŠ å…³é”®è¯æ£€ç´¢ç»“æœ
        for result in keyword_results:
            doc_id = result['id']
            if doc_id in all_results:
                all_results[doc_id]['keyword_score'] = result['similarity']
            else:
                all_results[doc_id] = {
                    'id': doc_id,
                    'document': result['document'],
                    'metadata': result['metadata'],
                    'vector_score': 0,
                    'keyword_score': result['similarity'],
                    'method': 'hybrid'
                }
        
        # 3. è®¡ç®—æ··åˆåˆ†æ•°
        for doc_id, result in all_results.items():
            result['hybrid_score'] = (
                result['vector_score'] * vector_weight +
                result['keyword_score'] * keyword_weight
            )
            result['similarity'] = result['hybrid_score']
        
        # 4. æ’åºå¹¶è¿”å›
        sorted_results = sorted(
            all_results.values(),
            key=lambda x: x['hybrid_score'],
            reverse=True
        )
        
        elapsed = time.time() - start_time
        return sorted_results[:n_results], elapsed
    
    def rerank_results(self, 
                      query: str,
                      results: List[Dict[str, Any]],
                      top_k: int = 5) -> List[Dict[str, Any]]:
        """
        é‡æ’åºï¼šä½¿ç”¨äº¤å‰ç¼–ç å™¨é‡æ–°æ’åºç»“æœ
        
        è¿™é‡Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬ï¼šåŸºäºæŸ¥è¯¢ä¸æ–‡æ¡£çš„è¯¦ç»†åŒ¹é…åº¦
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            results: åˆå§‹æ£€ç´¢ç»“æœ
            top_k: è¿”å›å‰Kä¸ªç»“æœ
            
        Returns:
            é‡æ’åºåçš„ç»“æœ
        """
        start_time = time.time()
        
        # è®¡ç®—é‡æ’åºåˆ†æ•°
        for result in results:
            doc = result['document']
            
            # åŸºäºå¤šä¸ªå› ç´ è®¡ç®—æ–°åˆ†æ•°
            rerank_score = result.get('similarity', 0.5) * 0.5  # åŸå§‹åˆ†æ•°å 50%
            
            # 1. æŸ¥è¯¢è¯å®Œå…¨åŒ¹é…ï¼ˆ+30%ï¼‰
            if query in doc:
                rerank_score += 0.3
            
            # 2. æŸ¥è¯¢è¯å­—ç¬¦è¦†ç›–ç‡ï¼ˆ+20%ï¼‰
            query_chars = set(query)
            doc_chars = set(doc)
            overlap = len(query_chars & doc_chars) / len(query_chars)
            rerank_score += overlap * 0.2
            
            result['rerank_score'] = min(rerank_score, 1.0)
        
        # é‡æ–°æ’åº
        results.sort(key=lambda x: x['rerank_score'], reverse=True)
        
        elapsed = time.time() - start_time
        
        # æ ‡è®°ä¸ºé‡æ’åºç»“æœ
        for result in results[:top_k]:
            result['method'] = result.get('method', 'unknown') + '+rerank'
            result['similarity'] = result['rerank_score']
        
        return results[:top_k], elapsed
    
    def search_with_context(self, 
                           query: str,
                           n_results: int = 5,
                           context_window: int = 1) -> List[Dict[str, Any]]:
        """
        å¸¦ä¸Šä¸‹æ–‡çª—å£çš„æ£€ç´¢
        
        è·å–åŒ¹é…å—åŠå…¶å‰åç›¸é‚»çš„å—ï¼Œæä¾›æ›´å®Œæ•´çš„ä¸Šä¸‹æ–‡
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            n_results: è¿”å›ç»“æœæ•°
            context_window: ä¸Šä¸‹æ–‡çª—å£å¤§å°ï¼ˆå‰åå„Nå—ï¼‰
            
        Returns:
            åŒ…å«ä¸Šä¸‹æ–‡çš„æ£€ç´¢ç»“æœ
        """
        start_time = time.time()
        
        # 1. å…ˆè¿›è¡Œæ··åˆæ£€ç´¢
        results, _ = self.hybrid_search(query, n_results=n_results)
        
        # 2. ä¸ºæ¯ä¸ªç»“æœæ·»åŠ ä¸Šä¸‹æ–‡
        for result in results:
            metadata = result['metadata']
            doc_name = metadata.get('doc_name')
            chunk_index = metadata.get('chunk_index')
            chunk_total = metadata.get('chunk_total')
            
            if doc_name is None or chunk_index is None:
                result['context_before'] = []
                result['context_after'] = []
                continue
            
            # è·å–å‰åæ–‡æ¡£å—
            context_before = []
            context_after = []
            
            # è·å–å‰é¢çš„å—
            for i in range(max(0, chunk_index - context_window), chunk_index):
                ctx_results = self.collection.get(
                    where={
                        "$and": [
                            {"doc_name": doc_name},
                            {"chunk_index": i}
                        ]
                    }
                )
                if ctx_results['documents']:
                    context_before.append(ctx_results['documents'][0])
            
            # è·å–åé¢çš„å—
            for i in range(chunk_index + 1, min(chunk_total, chunk_index + context_window + 1)):
                ctx_results = self.collection.get(
                    where={
                        "$and": [
                            {"doc_name": doc_name},
                            {"chunk_index": i}
                        ]
                    }
                )
                if ctx_results['documents']:
                    context_after.append(ctx_results['documents'][0])
            
            result['context_before'] = context_before
            result['context_after'] = context_after
            result['full_context'] = ''.join(context_before) + result['document'] + ''.join(context_after)
        
        elapsed = time.time() - start_time
        return results, elapsed


def demo():
    """æ¼”ç¤ºé«˜çº§æ£€ç´¢ç­–ç•¥"""
    print("=" * 60)
    print("RAGæœ€ç»ˆé¡¹ç›® - é«˜çº§æ£€ç´¢ç­–ç•¥æ¼”ç¤º")
    print("=" * 60)
    
    # åˆå§‹åŒ–æ£€ç´¢å™¨
    retriever = AdvancedRetriever()
    
    # æµ‹è¯•æŸ¥è¯¢
    test_queries = [
        "é†‰é©¾çš„å¤„ç½šæ˜¯ä»€ä¹ˆ",
        "å·¥ä½œæ—¶é—´",
        "åŠ ç­è´¹"
    ]
    
    for query in test_queries:
        print("\n" + "=" * 60)
        print(f"ğŸ” æŸ¥è¯¢: {query}")
        print("=" * 60)
        
        # 1. çº¯å‘é‡æ£€ç´¢
        print("\nğŸ“Š æ–¹æ³•1: çº¯å‘é‡æ£€ç´¢")
        print("-" * 50)
        vector_results, vector_time = retriever.vector_search(query, n_results=3)
        for i, result in enumerate(vector_results, 1):
            print(f"\nç»“æœ {i} (ç›¸ä¼¼åº¦: {result['similarity']:.1%})")
            print(f"æ¥æº: {result['metadata'].get('doc_name', 'unknown')}")
            print(f"å†…å®¹: {result['document'][:100]}...")
        print(f"\nâ±ï¸  è€—æ—¶: {vector_time*1000:.1f}ms")
        
        # 2. çº¯å…³é”®è¯æ£€ç´¢
        print("\nğŸ“Š æ–¹æ³•2: çº¯å…³é”®è¯æ£€ç´¢")
        print("-" * 50)
        keyword_results, keyword_time = retriever.keyword_search(query, n_results=3)
        for i, result in enumerate(keyword_results, 1):
            print(f"\nç»“æœ {i} (ç›¸ä¼¼åº¦: {result['similarity']:.1%})")
            print(f"æ¥æº: {result['metadata'].get('doc_name', 'unknown')}")
            print(f"å†…å®¹: {result['document'][:100]}...")
        print(f"\nâ±ï¸  è€—æ—¶: {keyword_time*1000:.1f}ms")
        
        # 3. æ··åˆæ£€ç´¢
        print("\nğŸ“Š æ–¹æ³•3: æ··åˆæ£€ç´¢ (å‘é‡70% + å…³é”®è¯30%)")
        print("-" * 50)
        hybrid_results, hybrid_time = retriever.hybrid_search(query, n_results=3)
        for i, result in enumerate(hybrid_results, 1):
            print(f"\nç»“æœ {i} (æ··åˆåˆ†: {result['similarity']:.1%})")
            print(f"  å‘é‡åˆ†: {result.get('vector_score', 0):.1%}")
            print(f"  å…³é”®è¯åˆ†: {result.get('keyword_score', 0):.1%}")
            print(f"æ¥æº: {result['metadata'].get('doc_name', 'unknown')}")
            print(f"å†…å®¹: {result['document'][:100]}...")
        print(f"\nâ±ï¸  è€—æ—¶: {hybrid_time*1000:.1f}ms")
        
        # 4. æ··åˆæ£€ç´¢ + é‡æ’åº
        print("\nğŸ“Š æ–¹æ³•4: æ··åˆæ£€ç´¢ + é‡æ’åº")
        print("-" * 50)
        hybrid_results, _ = retriever.hybrid_search(query, n_results=10)
        reranked_results, rerank_time = retriever.rerank_results(query, hybrid_results, top_k=3)
        for i, result in enumerate(reranked_results, 1):
            print(f"\nç»“æœ {i} (é‡æ’åˆ†: {result['similarity']:.1%})")
            print(f"  åŸå§‹æ··åˆåˆ†: {result.get('hybrid_score', 0):.1%}")
            print(f"æ¥æº: {result['metadata'].get('doc_name', 'unknown')}")
            print(f"å†…å®¹: {result['document'][:100]}...")
        print(f"\nâ±ï¸  é‡æ’åºè€—æ—¶: {rerank_time*1000:.1f}ms")
    
    # 5. ä¸Šä¸‹æ–‡çª—å£æ¼”ç¤º
    print("\n" + "=" * 60)
    print("ğŸªŸ ä¸Šä¸‹æ–‡çª—å£æ¼”ç¤º")
    print("=" * 60)
    query = "é†‰é©¾"
    print(f"\næŸ¥è¯¢: {query}")
    print("-" * 50)
    
    context_results, context_time = retriever.search_with_context(
        query, 
        n_results=2, 
        context_window=1
    )
    
    for i, result in enumerate(context_results, 1):
        print(f"\nç»“æœ {i}:")
        print(f"æ¥æº: {result['metadata'].get('doc_name', 'unknown')}")
        
        if result['context_before']:
            print(f"\nâ¬†ï¸  å‰æ–‡:")
            for ctx in result['context_before']:
                print(f"  {ctx[:80]}...")
        
        print(f"\nğŸ“Œ åŒ¹é…å— (ç›¸ä¼¼åº¦: {result['similarity']:.1%}):")
        print(f"  {result['document'][:150]}...")
        
        if result['context_after']:
            print(f"\nâ¬‡ï¸  åæ–‡:")
            for ctx in result['context_after']:
                print(f"  {ctx[:80]}...")
    
    print(f"\nâ±ï¸  è€—æ—¶: {context_time*1000:.1f}ms")
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("âœ… æ¼”ç¤ºå®Œæˆï¼")
    print("=" * 60)
    print("\nğŸ’¡ å­¦åˆ°çš„çŸ¥è¯†:")
    print("   1. çº¯å‘é‡æ£€ç´¢ï¼šè¯­ä¹‰ç†è§£å¥½ï¼Œä½†å¯èƒ½é”™è¿‡å…³é”®è¯")
    print("   2. çº¯å…³é”®è¯æ£€ç´¢ï¼šç²¾ç¡®åŒ¹é…ï¼Œä½†ç¼ºä¹è¯­ä¹‰ç†è§£")
    print("   3. æ··åˆæ£€ç´¢ï¼šç»“åˆä¸¤è€…ä¼˜åŠ¿ï¼Œæ•ˆæœæ›´å¥½")
    print("   4. é‡æ’åºï¼šè¿›ä¸€æ­¥ä¼˜åŒ–ç»“æœé¡ºåº")
    print("   5. ä¸Šä¸‹æ–‡çª—å£ï¼šæä¾›æ›´å®Œæ•´çš„ä¸Šä¸‹æ–‡ä¿¡æ¯")
    print("\nğŸ¯ æœ€ä½³å®è·µ:")
    print("   - çŸ­æŸ¥è¯¢/ç²¾ç¡®æŸ¥è¯¢ï¼šä½¿ç”¨æ··åˆæ£€ç´¢")
    print("   - é•¿æŸ¥è¯¢/è¯­ä¹‰æŸ¥è¯¢ï¼šå‘é‡æ£€ç´¢æƒé‡æ›´é«˜")
    print("   - éœ€è¦å®Œæ•´ä¿¡æ¯ï¼šå¯ç”¨ä¸Šä¸‹æ–‡çª—å£")
    print("   - å¯¹å‡†ç¡®ç‡è¦æ±‚é«˜ï¼šåŠ å…¥é‡æ’åº")
    print("\nä¸‹ä¸€æ­¥ï¼šæ„å»ºå®Œæ•´RAGåº”ç”¨ (03_rag_application.py)")


if __name__ == "__main__":
    demo()

