"""
ç»ƒä¹ 2ï¼šä½¿ç”¨Embeddingæ¨¡å‹
å­¦ä¹ å¦‚ä½•ä½¿ç”¨çœŸå®çš„ä¸­æ–‡Embeddingæ¨¡å‹æŠŠæ–‡æœ¬è½¬æˆå‘é‡
"""

from sentence_transformers import SentenceTransformer
import numpy as np

print("="*70)
print(" "*20 + "ä½¿ç”¨Embeddingæ¨¡å‹")
print("="*70)
print()

# 1. åŠ è½½æ¨¡å‹
print("="*70)
print("1. åŠ è½½ä¸­æ–‡Embeddingæ¨¡å‹")
print("="*70)
print()

print("æ­£åœ¨åŠ è½½æ¨¡å‹ï¼štext2vec-base-chinese")
print("ï¼ˆç¬¬ä¸€æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½ï¼Œçº¦400MBï¼Œéœ€è¦å‡ åˆ†é’Ÿï¼‰")
print()

try:
    model = SentenceTransformer('shibing624/text2vec-base-chinese')
    print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
except Exception as e:
    print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼š{e}")
    print()
    print("è§£å†³æ–¹æ¡ˆï¼š")
    print("1. ç¡®ä¿å·²å®‰è£…ï¼špip install sentence-transformers")
    print("2. æ£€æŸ¥ç½‘ç»œè¿æ¥")
    print("3. æˆ–ä½¿ç”¨å…¶ä»–æ¨¡å‹ï¼šparaphrase-multilingual-MiniLM-L12-v2")
    exit(1)

print()
print("æ¨¡å‹ä¿¡æ¯ï¼š")
print(f"  â€¢ æ¨¡å‹åç§°ï¼štext2vec-base-chinese")
print(f"  â€¢ å‘é‡ç»´åº¦ï¼š{model.get_sentence_embedding_dimension()}")
print(f"  â€¢ æ”¯æŒè¯­è¨€ï¼šä¸­æ–‡")
print()

# 2. æ–‡æœ¬è½¬å‘é‡
print("="*70)
print("2. æŠŠæ–‡æœ¬è½¬æ¢æˆå‘é‡")
print("="*70)
print()

text = "Pythonæ˜¯ä¸€ç§ç¼–ç¨‹è¯­è¨€"
print(f"åŸå§‹æ–‡æœ¬ï¼š{text}")
print()

# è½¬æ¢æˆå‘é‡
vector = model.encode(text)

print(f"å‘é‡ç»´åº¦ï¼š{len(vector)}")
print(f"å‘é‡ç±»å‹ï¼š{type(vector)}")
print()

print("å‘é‡å†…å®¹ï¼ˆå‰10ä¸ªå…ƒç´ ï¼‰ï¼š")
print(vector[:10])
print()

print("å‘é‡å†…å®¹ï¼ˆå10ä¸ªå…ƒç´ ï¼‰ï¼š")
print(vector[-10:])
print()

# å‘é‡çš„ç»Ÿè®¡ä¿¡æ¯
print("å‘é‡ç»Ÿè®¡ï¼š")
print(f"  â€¢ æœ€å°å€¼ï¼š{vector.min():.4f}")
print(f"  â€¢ æœ€å¤§å€¼ï¼š{vector.max():.4f}")
print(f"  â€¢ å¹³å‡å€¼ï¼š{vector.mean():.4f}")
print(f"  â€¢ æ ‡å‡†å·®ï¼š{vector.std():.4f}")
print()

# 3. æ‰¹é‡è½¬æ¢
print("="*70)
print("3. æ‰¹é‡è½¬æ¢å¤šä¸ªæ–‡æœ¬")
print("="*70)
print()

texts = [
    "Pythonæ˜¯ä¸€ç§ç¼–ç¨‹è¯­è¨€",
    "Javaä¹Ÿæ˜¯ç¼–ç¨‹è¯­è¨€",
    "æˆ‘å–œæ¬¢åƒè‹¹æœ",
    "æœºå™¨å­¦ä¹ å¾ˆæœ‰è¶£",
]

print("è¦è½¬æ¢çš„æ–‡æœ¬ï¼š")
for i, text in enumerate(texts, 1):
    print(f"  {i}. {text}")
print()

print("æ­£åœ¨æ‰¹é‡è½¬æ¢...")
vectors = model.encode(texts)
print(f"âœ… å®Œæˆï¼å¾—åˆ° {len(vectors)} ä¸ªå‘é‡")
print(f"   å‘é‡å½¢çŠ¶ï¼š{vectors.shape}")
print()

# 4. è®¡ç®—ç›¸ä¼¼åº¦
print("="*70)
print("4. è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦")
print("="*70)
print()

from sklearn.metrics.pairwise import cosine_similarity

# è®¡ç®—æ‰€æœ‰æ–‡æœ¬ä¸¤ä¸¤ä¹‹é—´çš„ç›¸ä¼¼åº¦
similarity_matrix = cosine_similarity(vectors)

print("ç›¸ä¼¼åº¦çŸ©é˜µï¼š")
print()
print(f"{'':25}", end="")
for i, text in enumerate(texts):
    print(f"{i+1:8}", end="")
print()

for i, text in enumerate(texts):
    print(f"{i+1}. {text:20}", end="")
    for j in range(len(texts)):
        print(f"{similarity_matrix[i][j]:8.3f}", end="")
    print()

print()
print("ğŸ’¡ è§‚å¯Ÿï¼š")
print("   â€¢ å¯¹è§’çº¿éƒ½æ˜¯1.000ï¼ˆè‡ªå·±å’Œè‡ªå·±å®Œå…¨ç›¸åŒï¼‰")
print("   â€¢ å¥å­1å’Œ2ç›¸ä¼¼åº¦é«˜ï¼ˆéƒ½æ˜¯ç¼–ç¨‹è¯­è¨€ï¼‰")
print("   â€¢ å¥å­3å’Œå…¶ä»–å·®å¼‚å¤§ï¼ˆä¸åŒä¸»é¢˜ï¼‰")
print()

# 5. æ‰¾æœ€ç›¸ä¼¼çš„æ–‡æœ¬
print("="*70)
print("5. å®æˆ˜ï¼šæ‰¾åˆ°æœ€ç›¸ä¼¼çš„æ–‡æœ¬")
print("="*70)
print()

query = "å­¦ä¹ ç¼–ç¨‹"
print(f"é—®é¢˜ï¼š{query}")
print()

# æŠŠé—®é¢˜ä¹Ÿè½¬æˆå‘é‡
query_vector = model.encode(query)

# è®¡ç®—é—®é¢˜å’Œæ¯ä¸ªæ–‡æœ¬çš„ç›¸ä¼¼åº¦
similarities = cosine_similarity([query_vector], vectors)[0]

print("ä¸å„æ–‡æœ¬çš„ç›¸ä¼¼åº¦ï¼š")
for text, sim in zip(texts, similarities):
    bar = "â–ˆ" * int(sim * 50)
    print(f"  [{sim:.3f}] {bar} {text}")

print()

# æ‰¾åˆ°æœ€ç›¸ä¼¼çš„
best_idx = similarities.argmax()
print(f"ğŸ¯ æœ€ç›¸ä¼¼çš„æ–‡æœ¬ï¼š{texts[best_idx]}")
print(f"   ç›¸ä¼¼åº¦ï¼š{similarities[best_idx]:.3f}")
print()

# 6. ä¸åŒæ–‡æœ¬çš„å¯¹æ¯”
print("="*70)
print("6. æµ‹è¯•ï¼šè¯­ä¹‰ç†è§£èƒ½åŠ›")
print("="*70)
print()

test_cases = [
    {
        "query": "å¦‚ä½•å­¦Python",
        "candidates": [
            "Pythonå­¦ä¹ æŒ‡å—",
            "Javaå¼€å‘æ•™ç¨‹",
            "Pythonå…¥é—¨æ–¹æ³•",
            "å¤©æ°”é¢„æŠ¥",
        ]
    },
    {
        "query": "å¤©æ°”æ€ä¹ˆæ ·",
        "candidates": [
            "ä»Šå¤©å¤©æ°”å¾ˆå¥½",
            "Pythonå¾ˆå¼ºå¤§",
            "æ°”å€™å˜åŒ–ç ”ç©¶",
            "æ˜å¤©ä¼šä¸‹é›¨",
        ]
    }
]

for case in test_cases:
    query = case["query"]
    candidates = case["candidates"]
    
    print(f"é—®é¢˜ï¼š{query}")
    print()
    
    # ç¼–ç 
    query_vec = model.encode(query)
    cand_vecs = model.encode(candidates)
    
    # è®¡ç®—ç›¸ä¼¼åº¦
    sims = cosine_similarity([query_vec], cand_vecs)[0]
    
    # æ’åº
    ranked = sorted(zip(candidates, sims), key=lambda x: x[1], reverse=True)
    
    print("æ’åºç»“æœï¼ˆæŒ‰ç›¸ä¼¼åº¦ï¼‰ï¼š")
    for i, (text, sim) in enumerate(ranked, 1):
        emoji = "ğŸ¥‡" if i == 1 else "ğŸ¥ˆ" if i == 2 else "ğŸ¥‰" if i == 3 else "  "
        print(f"  {emoji} [{sim:.3f}] {text}")
    print()

print("ğŸ’¡ è§‚å¯Ÿï¼š")
print("   â€¢ Embeddingæ¨¡å‹èƒ½ç†è§£è¯­ä¹‰ï¼Œä¸åªæ˜¯å…³é”®è¯åŒ¹é…")
print("   â€¢ 'å¦‚ä½•å­¦Python'å’Œ'Pythonå­¦ä¹ æŒ‡å—'ç›¸ä¼¼åº¦é«˜")
print("   â€¢ 'å¤©æ°”æ€ä¹ˆæ ·'èƒ½åŒ¹é…åˆ°'ä»Šå¤©å¤©æ°”å¾ˆå¥½'")
print()

# 7. ä¿å­˜å’ŒåŠ è½½å‘é‡
print("="*70)
print("7. ä¿å­˜å‘é‡ï¼ˆé¿å…é‡å¤è®¡ç®—ï¼‰")
print("="*70)
print()

# ä¿å­˜
vectors_file = "sample_vectors.npy"
np.save(vectors_file, vectors)
print(f"âœ… å‘é‡å·²ä¿å­˜åˆ°ï¼š{vectors_file}")

# åŠ è½½
loaded_vectors = np.load(vectors_file)
print(f"âœ… å‘é‡å·²åŠ è½½ï¼Œå½¢çŠ¶ï¼š{loaded_vectors.shape}")
print()

print("ğŸ’¡ å®é™…åº”ç”¨ä¸­ï¼š")
print("   â€¢ æ–‡æ¡£å‘é‡åªéœ€è®¡ç®—ä¸€æ¬¡ï¼Œä¿å­˜èµ·æ¥")
print("   â€¢ æŸ¥è¯¢æ—¶åªéœ€æŠŠé—®é¢˜è½¬æˆå‘é‡")
print("   â€¢ å¤§å¤§èŠ‚çœè®¡ç®—æ—¶é—´ï¼")
print()

# æ¸…ç†ä¸´æ—¶æ–‡ä»¶
import os
os.remove(vectors_file)
print(f"ï¼ˆå·²åˆ é™¤ä¸´æ—¶æ–‡ä»¶ï¼š{vectors_file}ï¼‰")
print()

# 8. æ€§èƒ½æµ‹è¯•
print("="*70)
print("8. æ€§èƒ½æµ‹è¯•")
print("="*70)
print()

import time

# å•ä¸ªæ–‡æœ¬
text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å¥å­"
start = time.time()
vec = model.encode(text)
time_single = time.time() - start

print(f"å•ä¸ªæ–‡æœ¬ç¼–ç ï¼š{time_single*1000:.2f}ms")

# æ‰¹é‡
texts_batch = [f"è¿™æ˜¯ç¬¬{i}ä¸ªæµ‹è¯•å¥å­" for i in range(100)]
start = time.time()
vecs = model.encode(texts_batch)
time_batch = time.time() - start

print(f"100ä¸ªæ–‡æœ¬æ‰¹é‡ç¼–ç ï¼š{time_batch*1000:.2f}ms")
print(f"å¹³å‡æ¯ä¸ªï¼š{time_batch/100*1000:.2f}ms")
print()

print(f"ğŸ’¡ æ‰¹é‡å¤„ç†å¿« {time_single*100/time_batch:.1f} å€ï¼")
print()

print("="*70)
print("âœ… ç»ƒä¹ 2å®Œæˆï¼")
print()
print("ğŸ’¡ å…³é”®æ”¶è·ï¼š")
print("   â€¢ å­¦ä¼šä½¿ç”¨SentenceTransformeråŠ è½½Embeddingæ¨¡å‹")
print("   â€¢ æ–‡æœ¬ â†’ å‘é‡è½¬æ¢ï¼ˆencodeæ–¹æ³•ï¼‰")
print("   â€¢ æ‰¹é‡å¤„ç†æ¯”å•ä¸ªå¤„ç†å¿«å¾ˆå¤š")
print("   â€¢ å‘é‡å¯ä»¥ä¿å­˜ï¼Œé¿å…é‡å¤è®¡ç®—")
print()
print("ğŸ“ ä¸‹ä¸€æ­¥ï¼špython 03_text_similarity.py")
print("   æ·±å…¥å­¦ä¹ ç›¸ä¼¼åº¦è®¡ç®—å’Œåº”ç”¨ï¼")
print("="*70)

