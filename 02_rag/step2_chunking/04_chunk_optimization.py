"""
ç»ƒä¹ 4ï¼šåˆ‡å—å‚æ•°è°ƒä¼˜
é€šè¿‡å®éªŒæ‰¾åˆ°æœ€ä¼˜çš„chunk_sizeå’Œoverlapå‚æ•°
"""

from langchain_text_splitters import RecursiveCharacterTextSplitter
import time

# è¾ƒé•¿çš„æµ‹è¯•æ–‡æœ¬
test_doc = """
# äººå·¥æ™ºèƒ½ç®€å²

## æ—©æœŸå‘å±•ï¼ˆ1950-1970ï¼‰

äººå·¥æ™ºèƒ½çš„æ¦‚å¿µæœ€æ—©å¯ä»¥è¿½æº¯åˆ°1950å¹´ï¼Œè‹±å›½æ•°å­¦å®¶è‰¾ä¼¦Â·å›¾çµå‘è¡¨äº†è‘—åçš„è®ºæ–‡ã€Šè®¡ç®—æœºå™¨ä¸æ™ºèƒ½ã€‹ï¼Œæå‡ºäº†"å›¾çµæµ‹è¯•"çš„æ¦‚å¿µã€‚1956å¹´ï¼Œçº¦ç¿°Â·éº¦å¡é”¡ç­‰äººåœ¨è¾¾ç‰¹èŒ…æ–¯ä¼šè®®ä¸Šæ­£å¼æå‡º"äººå·¥æ™ºèƒ½"è¿™ä¸€æœ¯è¯­ï¼Œæ ‡å¿—ç€AIä½œä¸ºä¸€ä¸ªç‹¬ç«‹å­¦ç§‘çš„è¯ç”Ÿã€‚

åœ¨è¿™ä¸€æ—¶æœŸï¼Œç ”ç©¶è€…ä»¬å¯¹AIå……æ»¡ä¹è§‚ã€‚ä»–ä»¬å¼€å‘äº†èƒ½å¤Ÿä¸‹æ£‹ã€è¯æ˜å®šç†çš„ç¨‹åºã€‚ç„¶è€Œï¼Œæ—©æœŸçš„AIç³»ç»ŸåŠŸèƒ½æœ‰é™ï¼Œä¸»è¦ä¾èµ–è§„åˆ™å’Œé€»è¾‘æ¨ç†ã€‚1966å¹´ï¼Œçº¦ç‘Ÿå¤«Â·é­å²‘é²å§†å¼€å‘çš„ELIZAç¨‹åºèƒ½å¤Ÿè¿›è¡Œç®€å•çš„å¯¹è¯ï¼Œè¿™æ˜¯æ—©æœŸè‡ªç„¶è¯­è¨€å¤„ç†çš„å°è¯•ã€‚

## ç¬¬ä¸€æ¬¡AIå¯’å†¬ï¼ˆ1970-1980ï¼‰

70å¹´ä»£ï¼ŒAIç ”ç©¶é­é‡äº†ç¬¬ä¸€æ¬¡å¯’å†¬ã€‚ç ”ç©¶è€…å‘ç°ï¼Œå¾ˆå¤šé—®é¢˜æ¯”é¢„æƒ³çš„å¤æ‚å¾—å¤šã€‚è®¡ç®—èƒ½åŠ›çš„é™åˆ¶ã€çŸ¥è¯†è¡¨ç¤ºçš„å›°éš¾ã€ä»¥åŠè¿‡åº¦ä¹è§‚çš„é¢„æœŸï¼Œå¯¼è‡´ç ”ç©¶èµ„é‡‘å¤§å¹…å‰Šå‡ã€‚è®¸å¤šAIé¡¹ç›®è¢«è¿«ä¸­æ–­ã€‚

ç„¶è€Œï¼Œè¿™ä¸€æ—¶æœŸä¹Ÿä¸ä¹äº®ç‚¹ã€‚ä¸“å®¶ç³»ç»Ÿå¼€å§‹å…´èµ·ï¼ŒMYCINç­‰åŒ»ç–—è¯Šæ–­ç³»ç»Ÿå±•ç¤ºäº†AIåœ¨ç‰¹å®šé¢†åŸŸçš„åº”ç”¨æ½œåŠ›ã€‚Prologç­‰é€»è¾‘ç¼–ç¨‹è¯­è¨€ä¹Ÿåœ¨è¿™ä¸ªæ—¶æœŸè¯ç”Ÿã€‚

## ä¸“å®¶ç³»ç»Ÿæ—¶ä»£ï¼ˆ1980-1990ï¼‰

80å¹´ä»£ï¼Œä¸“å®¶ç³»ç»Ÿæˆä¸ºAIçš„ä¸»æµåº”ç”¨ã€‚è¿™äº›ç³»ç»Ÿå°†äººç±»ä¸“å®¶çš„çŸ¥è¯†ç¼–ç æˆè§„åˆ™ï¼Œç”¨äºè§£å†³ç‰¹å®šé¢†åŸŸçš„é—®é¢˜ã€‚æ—¥æœ¬çš„"ç¬¬äº”ä»£è®¡ç®—æœº"è®¡åˆ’æŠ•å…¥å¤§é‡èµ„æºç ”å‘AIæŠ€æœ¯ã€‚

ä¸“å®¶ç³»ç»Ÿåœ¨åŒ»ç–—è¯Šæ–­ã€æ•…éšœæ£€æµ‹ã€é‡‘èåˆ†æç­‰é¢†åŸŸå–å¾—äº†ä¸€äº›æˆåŠŸã€‚ç„¶è€Œï¼Œè¿™äº›ç³»ç»Ÿçš„å±€é™æ€§ä¹Ÿé€æ¸æ˜¾ç°ï¼šçŸ¥è¯†è·å–å›°éš¾ã€ç»´æŠ¤æˆæœ¬é«˜ã€ç¼ºä¹å¸¸è¯†æ¨ç†èƒ½åŠ›ã€‚

## ç¬¬äºŒæ¬¡AIå¯’å†¬ï¼ˆ1990-2000ï¼‰

90å¹´ä»£åˆï¼Œéšç€ä¸“å®¶ç³»ç»Ÿçš„å±€é™æ€§æš´éœ²ï¼ŒAIå†æ¬¡è¿›å…¥å¯’å†¬ã€‚æ—¥æœ¬çš„ç¬¬äº”ä»£è®¡ç®—æœºé¡¹ç›®æœªèƒ½è¾¾åˆ°é¢„æœŸç›®æ ‡ã€‚ç ”ç©¶ç»è´¹å†æ¬¡å¤§å¹…å‰Šå‡ï¼Œ"AI"è¿™ä¸ªè¯åœ¨å­¦æœ¯ç•Œéƒ½å˜å¾—ä¸å—æ¬¢è¿ã€‚

ä½†åœ¨è¿™ä¸ªæ—¶æœŸï¼Œæœºå™¨å­¦ä¹ å¼€å§‹å´­éœ²å¤´è§’ã€‚æ”¯æŒå‘é‡æœºã€å†³ç­–æ ‘ç­‰ç®—æ³•å¾—åˆ°å‘å±•ã€‚äº’è”ç½‘çš„å…´èµ·ä¹Ÿä¸ºæ•°æ®é©±åŠ¨çš„AIæ–¹æ³•æä¾›äº†åŸºç¡€ã€‚

## æœºå™¨å­¦ä¹ å´›èµ·ï¼ˆ2000-2010ï¼‰

è¿›å…¥21ä¸–çºªï¼Œå¾—ç›Šäºè®¡ç®—èƒ½åŠ›çš„æå‡å’Œå¤§æ•°æ®çš„å‡ºç°ï¼Œæœºå™¨å­¦ä¹ å¼€å§‹å¿«é€Ÿå‘å±•ã€‚è°·æ­Œã€Facebookç­‰äº’è”ç½‘å…¬å¸å°†æœºå™¨å­¦ä¹ åº”ç”¨äºæœç´¢ã€æ¨èç­‰å®é™…åœºæ™¯ã€‚

2006å¹´ï¼ŒGeoffrey Hintonæå‡ºæ·±åº¦å­¦ä¹ çš„æ¦‚å¿µï¼Œä¸ºç¥ç»ç½‘ç»œçš„å¤å…´é“ºå¹³äº†é“è·¯ã€‚2009å¹´ï¼ŒImageNetæ•°æ®é›†å‘å¸ƒï¼Œä¸ºè®¡ç®—æœºè§†è§‰ç ”ç©¶æä¾›äº†å®è´µçš„èµ„æºã€‚

## æ·±åº¦å­¦ä¹ é©å‘½ï¼ˆ2010-2020ï¼‰

2012å¹´ï¼ŒAlex Krizhevskyä½¿ç”¨æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œåœ¨ImageNetç«èµ›ä¸­å–å¾—çªç ´æ€§æˆæœï¼Œæ ‡å¿—ç€æ·±åº¦å­¦ä¹ æ—¶ä»£çš„å¼€å§‹ã€‚æ­¤åï¼Œæ·±åº¦å­¦ä¹ åœ¨å›¾åƒè¯†åˆ«ã€è¯­éŸ³è¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†ç­‰é¢†åŸŸä¸æ–­åˆ·æ–°è®°å½•ã€‚

2016å¹´ï¼ŒAlphaGoå‡»è´¥ä¸–ç•Œå›´æ£‹å† å†›æä¸–çŸ³ï¼Œéœ‡æƒŠå…¨çƒã€‚2017å¹´ï¼ŒTransformeræ¶æ„çš„æå‡ºä¸ºè‡ªç„¶è¯­è¨€å¤„ç†å¸¦æ¥é©å‘½æ€§å˜åŒ–ã€‚2018å¹´ï¼ŒBERTæ¨¡å‹çš„å‘å¸ƒè¿›ä¸€æ­¥æ¨åŠ¨äº†NLPçš„å‘å±•ã€‚

## å¤§æ¨¡å‹æ—¶ä»£ï¼ˆ2020è‡³ä»Šï¼‰

2020å¹´ï¼ŒGPT-3çš„å‘å¸ƒå±•ç¤ºäº†å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹çš„æƒŠäººèƒ½åŠ›ã€‚è¿™äº›æ¨¡å‹é€šè¿‡åœ¨æµ·é‡æ–‡æœ¬ä¸Šè®­ç»ƒï¼Œèƒ½å¤Ÿå®Œæˆå„ç§è¯­è¨€ä»»åŠ¡ï¼ŒåŒ…æ‹¬ç¿»è¯‘ã€æ‘˜è¦ã€é—®ç­”ã€ç”šè‡³å†™ä»£ç ã€‚

2022å¹´æœ«ï¼ŒChatGPTçš„å‘å¸ƒå¼•å‘äº†å…¨çƒAIçƒ­æ½®ã€‚å¤§è¯­è¨€æ¨¡å‹å±•ç°å‡ºæ¥è¿‘äººç±»æ°´å¹³çš„å¯¹è¯å’Œæ¨ç†èƒ½åŠ›ã€‚2023å¹´ï¼ŒGPT-4è¿›ä¸€æ­¥æå‡äº†æ¨¡å‹çš„èƒ½åŠ›è¾¹ç•Œã€‚

ä¸æ­¤åŒæ—¶ï¼Œå›¾åƒç”Ÿæˆæ¨¡å‹å¦‚Stable Diffusionã€DALL-Eä¹Ÿå–å¾—äº†ä»¤äººç©ç›®çš„æˆæœã€‚å¤šæ¨¡æ€æ¨¡å‹èƒ½å¤ŸåŒæ—¶ç†è§£æ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ç­‰å¤šç§æ•°æ®ç±»å‹ã€‚

## æœªæ¥å±•æœ›

å½“å‰ï¼ŒAIæ­£åœ¨ç»å†å‰æ‰€æœªæœ‰çš„å‘å±•é»„é‡‘æœŸã€‚ä½†ä¹Ÿé¢ä¸´ç€è¯¸å¤šæŒ‘æˆ˜ï¼šå¦‚ä½•ç¡®ä¿AIçš„å®‰å…¨æ€§å’Œå¯æ§æ€§ï¼Ÿå¦‚ä½•åº”å¯¹AIå¸¦æ¥çš„å°±ä¸šå†²å‡»ï¼Ÿå¦‚ä½•è®©AIæ›´åŠ å…¬å¹³å’Œé€æ˜ï¼Ÿ

æœªæ¥çš„AIå‘å±•æ–¹å‘å¯èƒ½åŒ…æ‹¬ï¼šæ›´å¼ºå¤§çš„é€šç”¨äººå·¥æ™ºèƒ½ï¼ˆAGIï¼‰ã€æ›´é«˜æ•ˆçš„å°æ¨¡å‹ã€ä¸äººç±»æ›´å¥½åä½œçš„AIç³»ç»Ÿã€ä»¥åŠåœ¨å„è¡Œä¸šçš„æ·±åº¦åº”ç”¨ã€‚æ— è®ºå¦‚ä½•ï¼ŒAIå°†ç»§ç»­æ·±åˆ»åœ°æ”¹å˜æˆ‘ä»¬çš„ä¸–ç•Œã€‚
"""

print("="*70)
print(" "*20 + "åˆ‡å—å‚æ•°è°ƒä¼˜å®éªŒ")
print("="*70)
print()

print(f"ğŸ“„ æµ‹è¯•æ–‡æ¡£ï¼š")
print(f"   é•¿åº¦ï¼š{len(test_doc)} å­—ç¬¦")
print(f"   çº¦ {len(test_doc) // 500} ä¸ªè‡ªç„¶æ®µè½")
print()

# å®éªŒ1ï¼šæµ‹è¯•ä¸åŒçš„chunk_size
print("="*70)
print("å®éªŒ1ï¼šæµ‹è¯•ä¸åŒçš„ chunk_size")
print("="*70)
print()

chunk_sizes = [200, 300, 400, 500, 600, 800]
overlap = 50

print(f"å›ºå®š overlap={overlap}ï¼Œæµ‹è¯•ä¸åŒçš„ chunk_sizeï¼š\n")

results_size = []

for size in chunk_sizes:
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=size,
        chunk_overlap=overlap,
        separators=["\n## ", "\n### ", "\n\n", "\n", "ã€‚", " ", ""]
    )
    
    start_time = time.time()
    chunks = splitter.split_text(test_doc)
    time_cost = time.time() - start_time
    
    avg_size = sum(len(c) for c in chunks) / len(chunks)
    
    # æ£€æŸ¥è¯­ä¹‰å®Œæ•´æ€§ï¼ˆç®€å•è¯„ä¼°ï¼‰
    complete_sentences = sum(1 for c in chunks if c.strip().endswith(('ã€‚', '\n')))
    completeness = complete_sentences / len(chunks) * 100
    
    results_size.append({
        "chunk_size": size,
        "num_chunks": len(chunks),
        "avg_size": avg_size,
        "completeness": completeness,
        "time": time_cost
    })
    
    print(f"chunk_size={size:3d} â†’")
    print(f"   å—æ•°ï¼š{len(chunks):2d}")
    print(f"   å¹³å‡å¤§å°ï¼š{avg_size:5.1f} å­—ç¬¦")
    print(f"   å®Œæ•´æ€§ï¼š{completeness:5.1f}%")
    print(f"   è€—æ—¶ï¼š{time_cost*1000:5.1f}ms")
    print()

print("ğŸ’¡ è§‚å¯Ÿï¼š")
print("   â€¢ chunk_sizeè¶Šå°ï¼Œå—æ•°è¶Šå¤šï¼Œä½†æ¯å—æ›´å®Œæ•´")
print("   â€¢ chunk_sizeè¶Šå¤§ï¼Œå—æ•°è¶Šå°‘ï¼Œä½†å¯èƒ½æ··åˆå¤šä¸ªä¸»é¢˜")
print("   â€¢ æ¨èï¼š300-500å­—ç¬¦å¯¹äºä¸­æ–‡æ–‡æ¡£æ¯”è¾ƒåˆé€‚")
print()

# å®éªŒ2ï¼šæµ‹è¯•ä¸åŒçš„overlap
print("="*70)
print("å®éªŒ2ï¼šæµ‹è¯•ä¸åŒçš„ overlap")
print("="*70)
print()

chunk_size = 400
overlaps = [0, 20, 40, 60, 80, 100]

print(f"å›ºå®š chunk_size={chunk_size}ï¼Œæµ‹è¯•ä¸åŒçš„ overlapï¼š\n")

results_overlap = []

for overlap in overlaps:
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=overlap,
        separators=["\n## ", "\n### ", "\n\n", "\n", "ã€‚", " ", ""]
    )
    
    chunks = splitter.split_text(test_doc)
    
    # è®¡ç®—å®é™…çš„é‡å å†…å®¹
    actual_overlaps = []
    for i in range(len(chunks) - 1):
        # æ£€æŸ¥å—2çš„å¼€å¤´éƒ¨åˆ†æ˜¯å¦åœ¨å—1ä¸­å‡ºç°
        chunk2_start = chunks[i+1][:overlap+50]  # å¤šå–ä¸€äº›ä»¥ç¡®ä¿èƒ½æ‰¾åˆ°
        chunk1 = chunks[i]
        
        # ä»é•¿åˆ°çŸ­å°è¯•æ‰¾åˆ°æœ€é•¿çš„å…¬å…±éƒ¨åˆ†
        common_len = 0
        for length in range(min(len(chunk2_start), overlap+50), 0, -1):
            test_str = chunk2_start[:length]
            if test_str in chunk1:
                common_len = length
                break
        
        actual_overlaps.append(common_len)
    
    avg_overlap = sum(actual_overlaps) / len(actual_overlaps) if actual_overlaps else 0
    
    results_overlap.append({
        "overlap": overlap,
        "num_chunks": len(chunks),
        "avg_actual_overlap": avg_overlap,
        "overlap_rate": (avg_overlap / chunk_size * 100) if chunk_size > 0 else 0
    })
    
    print(f"overlap={overlap:3d} ({overlap/chunk_size*100:4.1f}%) â†’")
    print(f"   å—æ•°ï¼š{len(chunks):2d}")
    print(f"   å®é™…å¹³å‡é‡å ï¼š{avg_overlap:5.1f} å­—ç¬¦")
    print(f"   é‡å ç‡ï¼š{avg_overlap/chunk_size*100:5.1f}%")
    print()

print("ğŸ’¡ è§‚å¯Ÿï¼š")
print("   â€¢ overlapå¢åŠ ï¼Œå—æ•°å¢åŠ ï¼ˆå› ä¸ºæ­¥é•¿å‡å°ï¼‰")
print("   â€¢ è¿‡å¤§çš„overlapä¼šé€ æˆå­˜å‚¨æµªè´¹")
print("   â€¢ æ¨èï¼šchunk_sizeçš„15-20%")
print()

# å®éªŒ3ï¼šç»¼åˆè¯„åˆ†
print("="*70)
print("å®éªŒ3ï¼šç»¼åˆè¯„åˆ†ï¼ˆæ‰¾æœ€ä¼˜å‚æ•°ï¼‰")
print("="*70)
print()

print("è¯„åˆ†ç»´åº¦ï¼š")
print("   1. å—æ•°é€‚ä¸­ï¼ˆä¸è¦å¤ªå¤šä¹Ÿä¸è¦å¤ªå°‘ï¼‰")
print("   2. è¯­ä¹‰å®Œæ•´æ€§é«˜")
print("   3. åˆ‡å—é€Ÿåº¦å¿«")
print()

configs = [
    (200, 30),
    (300, 45),
    (400, 60),
    (500, 75),
    (600, 90)
]

print(f"{'é…ç½®':15} {'å—æ•°':6} {'å®Œæ•´æ€§':8} {'è€—æ—¶':8} {'ç»¼åˆå¾—åˆ†':10}")
print("â”€" * 60)

best_score = 0
best_config = None

for chunk_size, overlap in configs:
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=overlap,
        separators=["\n## ", "\n### ", "\n\n", "\n", "ã€‚", " ", ""]
    )
    
    start_time = time.time()
    chunks = splitter.split_text(test_doc)
    time_cost = time.time() - start_time
    
    # è®¡ç®—å®Œæ•´æ€§
    complete = sum(1 for c in chunks if c.strip().endswith(('ã€‚', '\n', '#')))
    completeness = complete / len(chunks) * 100
    
    # ç»¼åˆè¯„åˆ†ï¼ˆç®€åŒ–ç‰ˆï¼‰
    # å—æ•°å¾—åˆ†ï¼š15-25å—æœ€ä¼˜
    num_score = max(0, 100 - abs(len(chunks) - 20) * 5)
    # å®Œæ•´æ€§å¾—åˆ†
    comp_score = completeness
    # é€Ÿåº¦å¾—åˆ†ï¼ˆè¶Šå¿«è¶Šå¥½ï¼‰
    speed_score = max(0, 100 - time_cost * 10000)
    
    total_score = (num_score * 0.3 + comp_score * 0.5 + speed_score * 0.2)
    
    if total_score > best_score:
        best_score = total_score
        best_config = (chunk_size, overlap)
    
    config_str = f"{chunk_size}/{overlap}"
    print(f"{config_str:15} {len(chunks):6d} {completeness:7.1f}% {time_cost*1000:7.1f}ms {total_score:9.1f}")

print("â”€" * 60)
print()
print(f"ğŸ† æœ€ä¼˜é…ç½®ï¼šchunk_size={best_config[0]}, overlap={best_config[1]}")
print(f"   ç»¼åˆå¾—åˆ†ï¼š{best_score:.1f}")
print()

# å®éªŒ4ï¼šä¸åŒç±»å‹æ–‡æ¡£çš„æ¨èé…ç½®
print("="*70)
print("å®éªŒ4ï¼šä¸åŒæ–‡æ¡£ç±»å‹çš„æ¨èé…ç½®")
print("="*70)
print()

recommendations = [
    {
        "type": "FAQ/é—®ç­”å¯¹",
        "chunk_size": 250,
        "overlap": 30,
        "reason": "æ¯ä¸ªé—®ç­”æ˜¯ç‹¬ç«‹å•å…ƒï¼Œè¾ƒå°çš„å—æ›´ç²¾ç¡®"
    },
    {
        "type": "æŠ€æœ¯æ–‡æ¡£",
        "chunk_size": 500,
        "overlap": 75,
        "reason": "éœ€è¦å®Œæ•´çš„æŠ€æœ¯è¯´æ˜ï¼Œä¸Šä¸‹æ–‡å¾ˆé‡è¦"
    },
    {
        "type": "æ–°é—»æ–‡ç« ",
        "chunk_size": 400,
        "overlap": 60,
        "reason": "é€šå¸¸ä¸€æ®µä¸€ä¸ªä¸»é¢˜ï¼Œä¸­ç­‰å¤§å°åˆé€‚"
    },
    {
        "type": "å­¦æœ¯è®ºæ–‡",
        "chunk_size": 600,
        "overlap": 100,
        "reason": "è®ºè¿°å®Œæ•´ï¼Œéœ€è¦è¾ƒå¤§çš„ä¸Šä¸‹æ–‡çª—å£"
    },
    {
        "type": "å¯¹è¯è®°å½•",
        "chunk_size": 350,
        "overlap": 50,
        "reason": "ä¿ç•™å¯¹è¯çš„è¿è´¯æ€§ï¼Œä¸­ç­‰åå°"
    }
]

for rec in recommendations:
    print(f"ğŸ“š {rec['type']}")
    print(f"   æ¨èé…ç½®ï¼šchunk_size={rec['chunk_size']}, overlap={rec['overlap']}")
    print(f"   åŸå› ï¼š{rec['reason']}")
    print()

print("="*70)
print("âœ… ç»ƒä¹ 4å®Œæˆï¼")
print()
print("ğŸ’¡ æ ¸å¿ƒæ”¶è·ï¼š")
print("   â€¢ chunk_size: ä¸­æ–‡æ–‡æ¡£æ¨è300-500å­—")
print("   â€¢ overlap: æ¨èchunk_sizeçš„15-20%")
print("   â€¢ ä¸åŒç±»å‹æ–‡æ¡£éœ€è¦ä¸åŒé…ç½®")
print("   â€¢ è¦åœ¨å—æ•°ã€å®Œæ•´æ€§ã€æ€§èƒ½é—´å¹³è¡¡")
print()
print("ğŸ‰ Step 2 å…¨éƒ¨å®Œæˆï¼")
print()
print("ğŸ“Š Step 2 æ€»ç»“ï¼š")
print("   âœ… ç†è§£äº†ä¸ºä»€ä¹ˆè¦åˆ‡å—")
print("   âœ… æŒæ¡äº†3ç§åˆ‡å—æ–¹æ³•")
print("   âœ… å­¦ä¼šäº†å¤„ç†çœŸå®æ–‡æ¡£")
print("   âœ… èƒ½å¤Ÿä¼˜åŒ–åˆ‡å—å‚æ•°")
print()
print("ğŸ“ ä¸‹ä¸€æ­¥ï¼šStep 3 - å‘é‡åŒ–ï¼ˆEmbeddingï¼‰")
print("   å‘½ä»¤ï¼šcd ../step3_embedding && cat README.md")
print()
print("="*70)

