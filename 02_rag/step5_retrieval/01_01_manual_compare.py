#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Step 5.1.1: æ‰‹åŠ¨å¯¹æ¯”RAGæ•ˆæœ
å­¦ä¹ ç›®æ ‡ï¼šè®©ç”¨æˆ·è‡ªå·±è¾“å…¥é—®é¢˜ï¼Œç›´è§‚å¯¹æ¯”æœ‰æ— RAGçš„å·®å¼‚
"""

import chromadb
from sentence_transformers import SentenceTransformer
from llama_cpp import Llama
import os

print("=" * 60)
print("ğŸ”¬ æ‰‹åŠ¨å¯¹æ¯”ï¼šç›´æ¥é—®LLM vs ä½¿ç”¨RAG")
print("=" * 60)

# ============================================================
# åŠ è½½ç»„ä»¶
# ============================================================

print("\nğŸ“¦ åŠ è½½ç³»ç»Ÿç»„ä»¶...")

# 1. å‘é‡æ•°æ®åº“
print("   [1/3] åŠ è½½å‘é‡æ•°æ®åº“...")
db_path = "../step4_vectorstore/data/chroma_traffic_law"

if not os.path.exists(db_path):
    print("âŒ é”™è¯¯ï¼šå‘é‡æ•°æ®åº“ä¸å­˜åœ¨ï¼")
    print(f"   è¯·å…ˆè¿è¡Œ: cd ../step4_vectorstore && python 02_import_traffic_law.py")
    exit(1)

client = chromadb.PersistentClient(path=db_path)
collection = client.get_collection(name="traffic_law")
print(f"         âœ… æ•°æ®åº“åŒ…å« {collection.count()} ä¸ªæ–‡æ¡£")

# 2. Embeddingæ¨¡å‹
print("   [2/3] åŠ è½½Embeddingæ¨¡å‹...")
embedding_model = SentenceTransformer('shibing624/text2vec-base-chinese')
print("         âœ… Embeddingæ¨¡å‹åŠ è½½å®Œæˆ")

# 3. LLM
print("   [3/3] åŠ è½½LLM...")
llm_path = "/Users/a58/llama.cpp/models/qwen2.5-3b-instruct-q4_k_m.gguf"

if not os.path.exists(llm_path):
    print("âŒ é”™è¯¯ï¼šLLMæ¨¡å‹ä¸å­˜åœ¨ï¼")
    print(f"   è¯·æ£€æŸ¥è·¯å¾„: {llm_path}")
    exit(1)

llm = Llama(
    model_path=llm_path,
    n_ctx=2048,
    n_threads=4,
    n_gpu_layers=0,
    verbose=False
)
print("         âœ… LLMåŠ è½½å®Œæˆ")

print("\nâœ… æ‰€æœ‰ç»„ä»¶åŠ è½½å®Œæˆï¼\n")

# ============================================================
# å®šä¹‰å‡½æ•°
# ============================================================

def ask_llm_directly(question):
    """
    ç›´æ¥é—®LLMï¼ˆä¸ä½¿ç”¨RAGï¼‰
    
    Args:
        question: ç”¨æˆ·é—®é¢˜
    
    Returns:
        LLMçš„ç›´æ¥å›ç­”
    """
    prompt = f"{question}\n\nè¯·å›ç­”ï¼š"
    
    output = llm(
        prompt,
        max_tokens=200,
        temperature=0.7,  # è¾ƒé«˜æ¸©åº¦
        stop=["\n\n"],
        echo=False,
        stream=False
    )
    
    return output['choices'][0]['text'].strip()


def ask_with_rag(question):
    """
    ä½¿ç”¨RAGå›ç­”é—®é¢˜
    
    Args:
        question: ç”¨æˆ·é—®é¢˜
    
    Returns:
        tuple: (RAGç­”æ¡ˆ, æ£€ç´¢åˆ°çš„æ–‡æ¡£)
    """
    # Step 1: å‘é‡åŒ–é—®é¢˜
    question_vector = embedding_model.encode([question], show_progress_bar=False)
    
    # Step 2: æ£€ç´¢ç›¸å…³æ–‡æ¡£ï¼ˆé™ä½é˜ˆå€¼ï¼Œå…è®¸æ›´å¤šç»“æœï¼‰
    results = collection.query(
        query_embeddings=question_vector.tolist(),
        n_results=5,  # å¢åŠ æ£€ç´¢æ•°é‡
        include=["documents", "metadatas", "distances"]
    )
    
    # æ ¼å¼åŒ–æ£€ç´¢ç»“æœï¼Œè¿‡æ»¤ä½ç›¸ä¼¼åº¦ï¼ˆé˜ˆå€¼0.5ï¼‰
    retrieved_docs = []
    for i in range(len(results['ids'][0])):
        similarity = 1 - results['distances'][0][i]
        if similarity >= 0.5:  # é˜ˆå€¼0.5ï¼Œå…è®¸æ›´å®½æ¾çš„åŒ¹é…
            retrieved_docs.append({
                'content': results['documents'][0][i],
                'chapter': results['metadatas'][0][i]['chapter'],
                'similarity': similarity
            })
    
    # æœ€å¤šä¿ç•™3ä¸ªæœ€ç›¸ä¼¼çš„
    retrieved_docs = retrieved_docs[:3]
    
    # Step 3: æ„å»ºä¸Šä¸‹æ–‡
    context = "\n\n".join([doc['content'] for doc in retrieved_docs])
    
    # Step 4: ç”Ÿæˆç­”æ¡ˆ
    prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„äº¤é€šæ³•è§„åŠ©æ‰‹ï¼Œä¸“é—¨è§£ç­”ä¸­å›½é“è·¯äº¤é€šå®‰å…¨æ³•ç›¸å…³é—®é¢˜ã€‚

ã€å‚è€ƒèµ„æ–™ã€‘
{context}

ã€å›ç­”è§„åˆ™ã€‘
1. ä¸¥æ ¼ä¾æ®å‚è€ƒèµ„æ–™å›ç­”ï¼Œä¸ç¼–é€ ä¿¡æ¯
2. å¦‚æœå‚è€ƒèµ„æ–™ä¸­æ²¡æœ‰ç›¸å…³å†…å®¹ï¼Œæ˜ç¡®å›ç­”ã€Œå‚è€ƒèµ„æ–™ä¸­æœªæåŠæ­¤å†…å®¹ã€
3. å›ç­”è¦å‡†ç¡®ã€ç®€æ´ã€åˆ†ç‚¹åˆ—å‡º
4. ä¿æŒå®¢è§‚ä¸­ç«‹çš„è¯­æ°”

ã€ç”¨æˆ·é—®é¢˜ã€‘
{question}

ã€ä½ çš„å›ç­”ã€‘
"""
    
    output = llm(
        prompt,
        max_tokens=256,
        temperature=0.3,  # ä½æ¸©åº¦ï¼Œæ›´ç¡®å®š
        stop=["ã€", "\n\n\n"],
        echo=False,
        stream=False
    )
    
    answer = output['choices'][0]['text'].strip()
    
    return answer, retrieved_docs, prompt  # è¿”å›promptç”¨äºæ˜¾ç¤º


# ============================================================
# äº¤äº’å¼å¯¹æ¯”
# ============================================================

print("=" * 60)
print("ğŸ¯ ä½¿ç”¨è¯´æ˜")
print("=" * 60)
print("\nç°åœ¨ä½ å¯ä»¥è¾“å…¥ä»»ä½•å…³äºäº¤é€šæ³•çš„é—®é¢˜ï¼Œç³»ç»Ÿä¼šå±•ç¤ºä¸¤ç§å›ç­”ï¼š")
print("   1ï¸âƒ£  ç›´æ¥é—®LLMï¼ˆæ²¡æœ‰å‚è€ƒèµ„æ–™ï¼‰")
print("   2ï¸âƒ£  ä½¿ç”¨RAGï¼ˆåŸºäºäº¤é€šæ³•æ–‡æ¡£ï¼‰")
print("\nç„¶åä½ å¯ä»¥å¯¹æ¯”ä¸¤è€…çš„å·®å¼‚ï¼")
print("\nğŸ’¡ è¾“å…¥ 'exit' æˆ– 'quit' é€€å‡º")
print("ğŸ’¡ è¾“å…¥ 'examples' æŸ¥çœ‹ç¤ºä¾‹é—®é¢˜")
print("\n" + "=" * 60)

# ç¤ºä¾‹é—®é¢˜
example_questions = [
    "é…’é©¾çš„å¤„ç½šæ˜¯ä»€ä¹ˆï¼Ÿ",
    "é—¯çº¢ç¯è¦æ‰£å‡ åˆ†ï¼Ÿ",
    "é©¾é©¶è¯æ‰£æ»¡12åˆ†æ€ä¹ˆåŠï¼Ÿ",
    "äº¤é€šäº‹æ•…ååº”è¯¥æ€ä¹ˆå¤„ç†ï¼Ÿ",
    "è¶…é€Ÿ50%ä»¥ä¸Šä¼šè¢«æ€ä¹ˆå¤„ç½šï¼Ÿ",
]

# ä¸»å¾ªç¯
while True:
    try:
        # è·å–ç”¨æˆ·è¾“å…¥
        print("\n" + "â”€" * 60)
        user_question = input("\nğŸ’¬ è¯·è¾“å…¥ä½ çš„é—®é¢˜: ").strip()
        
        # å¤„ç†é€€å‡º
        if user_question.lower() in ['exit', 'quit', 'bye']:
            print("\nğŸ‘‹ å†è§ï¼\n")
            break
        
        # æ˜¾ç¤ºç¤ºä¾‹
        if user_question.lower() == 'examples':
            print("\nğŸ“ ç¤ºä¾‹é—®é¢˜:")
            for i, q in enumerate(example_questions, 1):
                print(f"   {i}. {q}")
            continue
        
        # å¤„ç†ç©ºè¾“å…¥
        if not user_question:
            print("âš ï¸  è¯·è¾“å…¥é—®é¢˜")
            continue
        
        print("\n" + "=" * 60)
        print(f"â“ ä½ çš„é—®é¢˜: {user_question}")
        print("=" * 60)
        
        # ============================================================
        # æ–¹å¼1ï¼šç›´æ¥é—®LLM
        # ============================================================
        
        print("\n" + "â”" * 60)
        print("æ–¹å¼1ï¸âƒ£ : ç›´æ¥é—®LLMï¼ˆä¸ä½¿ç”¨RAGï¼‰")
        print("â”" * 60)
        print("\nğŸ¤– æ­£åœ¨ç”Ÿæˆ...")
        
        answer_direct = ask_llm_directly(user_question)
        
        print(f"\nğŸ’¬ LLMç›´æ¥å›ç­”:")
        print("â”Œ" + "â”€" * 58 + "â”")
        for line in answer_direct.split('\n'):
            print(f"â”‚ {line:<56} â”‚")
        print("â””" + "â”€" * 58 + "â”˜")
        
        print("\nğŸ“Œ ç‰¹ç‚¹:")
        print("   â€¢ åŸºäºæ¨¡å‹è‡ªèº«çš„è®­ç»ƒæ•°æ®")
        print("   â€¢ å¯èƒ½åŒ…å«æ¨¡å‹çš„ã€Œè®°å¿†ã€æˆ–ã€ŒçŒœæµ‹ã€")
        print("   â€¢ æ— æ³•éªŒè¯ç­”æ¡ˆæ¥æº")
        print("   â€¢ ä¿¡æ¯å¯èƒ½è¿‡æ—¶æˆ–ä¸å‡†ç¡®")
        
        # ============================================================
        # æ–¹å¼2ï¼šä½¿ç”¨RAG
        # ============================================================
        
        print("\n" + "â”" * 60)
        print("æ–¹å¼2ï¸âƒ£ : ä½¿ç”¨RAGï¼ˆåŸºäºäº¤é€šæ³•æ–‡æ¡£ï¼‰")
        print("â”" * 60)
        
        print("\nğŸ” Step 1: æ£€ç´¢ç›¸å…³æ–‡æ¡£...")
        answer_rag, retrieved_docs, rag_prompt = ask_with_rag(user_question)
        
        print(f"\nğŸ“š æ£€ç´¢åˆ° {len(retrieved_docs)} ä¸ªç›¸å…³æ–‡æ¡£:")
        for i, doc in enumerate(retrieved_docs, 1):
            print(f"\n   [{i}] ç›¸ä¼¼åº¦: {doc['similarity']*100:.1f}% | {doc['chapter']}")
            preview = doc['content'][:80].replace('\n', ' ') + "..." if len(doc['content']) > 80 else doc['content']
            print(f"       é¢„è§ˆ: {preview}")
        
        print("\nğŸ“ Step 2: æ„å»ºPromptï¼ˆæŠŠæ£€ç´¢åˆ°çš„ç‰‡æ®µå¡è¿›å»ï¼‰...")
        print("â”Œ" + "â”€" * 58 + "â”")
        print("â”‚ ğŸ” Promptå†…å®¹é¢„è§ˆï¼ˆå‰500å­—ç¬¦ï¼‰:                         â”‚")
        print("â”œ" + "â”€" * 58 + "â”¤")
        prompt_preview = rag_prompt[:500].replace('\n', '\nâ”‚ ')
        for line in prompt_preview.split('\n'):
            print(f"â”‚ {line:<56} â”‚")
        if len(rag_prompt) > 500:
            print(f"â”‚ ... (è¿˜æœ‰ {len(rag_prompt)-500} å­—ç¬¦)                               â”‚")
        print("â””" + "â”€" * 58 + "â”˜")
        
        print(f"\n   â€¢ Promptæ€»é•¿åº¦: {len(rag_prompt)} å­—ç¬¦")
        print(f"   â€¢ åŒ…å«çš„æ–‡æ¡£ç‰‡æ®µæ•°: {len(retrieved_docs)} ä¸ª")
        
        print("\nğŸ¤– Step 3: LLMåŸºäºè¿™ä¸ªPromptç”Ÿæˆç­”æ¡ˆ...")
        
        print(f"\nğŸ’¡ RAGå›ç­”:")
        print("â”Œ" + "â”€" * 58 + "â”")
        for line in answer_rag.split('\n'):
            print(f"â”‚ {line:<56} â”‚")
        print("â””" + "â”€" * 58 + "â”˜")
        
        print("\nğŸ“Œ ç‰¹ç‚¹:")
        print("   â€¢ åŸºäºæœ€æ–°çš„äº¤é€šæ³•æ–‡æ¡£")
        print("   â€¢ ç­”æ¡ˆæœ‰æ®å¯æŸ¥")
        print("   â€¢ å¯ä»¥è¿½æº¯åˆ°å…·ä½“ç« èŠ‚")
        print("   â€¢ æ›´å‡†ç¡®ã€æ›´å¯ä¿¡")
        
        # ============================================================
        # å¯¹æ¯”åˆ†æ
        # ============================================================
        
        print("\n" + "=" * 60)
        print("ğŸ“Š å¯¹æ¯”åˆ†æ")
        print("=" * 60)
        
        print(f"\nç›´æ¥é—®LLM:")
        print(f"   é•¿åº¦: {len(answer_direct)} å­—ç¬¦")
        print(f"   æ¸©åº¦: 0.7ï¼ˆè¾ƒéšæœºï¼‰")
        print(f"   æ¥æº: æ¨¡å‹è®°å¿†")
        
        print(f"\nä½¿ç”¨RAG:")
        print(f"   é•¿åº¦: {len(answer_rag)} å­—ç¬¦")
        print(f"   æ¸©åº¦: 0.3ï¼ˆæ›´ç¡®å®šï¼‰")
        print(f"   æ¥æº: {len(retrieved_docs)} ä¸ªæ–‡æ¡£ç‰‡æ®µ")
        
        print(f"\nğŸ’¡ ä½ è§‰å¾—å“ªä¸ªç­”æ¡ˆæ›´å¥½ï¼Ÿ")
        print(f"   â€¢ ç›´æ¥é—®LLM: å¯èƒ½æµç•…ä½†ä¸ä¸€å®šå‡†ç¡®")
        print(f"   â€¢ ä½¿ç”¨RAG: åŸºäºæƒå¨æ–‡æ¡£ï¼Œæ›´å¯ä¿¡")
        
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ æ£€æµ‹åˆ°Ctrl+Cï¼Œé€€å‡º\n")
        break
    
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        print("è¯·é‡è¯•æˆ–è¾“å…¥ 'exit' é€€å‡º\n")
        continue

# ============================================================
# æ€»ç»“
# ============================================================

print("\n" + "=" * 60)
print("ğŸ‰ å¯¹æ¯”ä½“éªŒå®Œæˆï¼")
print("=" * 60)

print("\nâœ… é€šè¿‡å¯¹æ¯”ï¼Œä½ åº”è¯¥å‘ç°äº†:")
print("   1. LLMç›´æ¥å›ç­”å¯èƒ½ã€Œå¬èµ·æ¥å¯¹ã€ï¼Œä½†ä¸ä¸€å®šå‡†ç¡®")
print("   2. RAGæä¾›æœ‰ä¾æ®çš„å›ç­”ï¼Œå¯ä»¥è¿½æº¯æ¥æº")
print("   3. RAGçš„temperatureæ›´ä½ï¼Œæ›´å¿ å®äºæ–‡æ¡£")
print("   4. RAGèƒ½é˜²æ­¢æ¨¡å‹ã€Œç¼–é€ ã€ä¿¡æ¯")

print("\nğŸ’¡ RAGçš„æ ¸å¿ƒä»·å€¼:")
print("   â€¢ è®©LLMå›ç­”ã€Œæœ‰æ®å¯æŸ¥ã€")
print("   â€¢ é˜²æ­¢æ¨¡å‹å¹»è§‰ï¼ˆç¼–é€ ï¼‰")
print("   â€¢ å¯ä»¥ä½¿ç”¨æœ€æ–°çš„ã€é¢†åŸŸä¸“å±çš„æ–‡æ¡£")
print("   â€¢ æå‡ç­”æ¡ˆçš„å‡†ç¡®æ€§å’Œå¯ä¿¡åº¦")

print("\nğŸ¯ ä¸‹ä¸€æ­¥:")
print("   è¿è¡Œ: python 01_basic_rag.py")
print("   æˆ–è€…: python 02_improve_retrieval.py")
print("   ç»§ç»­æ·±å…¥å­¦ä¹ RAGä¼˜åŒ–æŠ€å·§")

print("\n" + "=" * 60)

