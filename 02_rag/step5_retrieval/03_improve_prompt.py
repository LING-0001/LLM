#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Step 5.3: ä¼˜åŒ–Promptæå‡ç”Ÿæˆè´¨é‡
å­¦ä¹ ç›®æ ‡ï¼šé€šè¿‡Promptå·¥ç¨‹é˜²æ­¢å¹»è§‰ã€æå‡ç­”æ¡ˆè´¨é‡
"""

import chromadb
from sentence_transformers import SentenceTransformer
from llama_cpp import Llama
import os

print("=" * 60)
print("âœ¨ Promptä¼˜åŒ–æå‡RAGè´¨é‡")
print("=" * 60)

# ============================================================
# åŠ è½½ç»„ä»¶
# ============================================================

print("\nğŸ“¦ åŠ è½½ç³»ç»Ÿç»„ä»¶...")

db_path = "../step4_vectorstore/data/chroma_traffic_law"
client = chromadb.PersistentClient(path=db_path)
collection = client.get_collection(name="traffic_law")

embedding_model = SentenceTransformer('shibing624/text2vec-base-chinese')

llm = Llama(
    model_path="/Users/a58/llama.cpp/models/qwen2.5-3b-instruct-q4_k_m.gguf",
    n_ctx=2048,
    n_threads=4,
    n_gpu_layers=0,
    verbose=False
)

print("âœ… æ‰€æœ‰ç»„ä»¶åŠ è½½å®Œæˆ\n")

# ============================================================
# æ£€ç´¢å‡½æ•°
# ============================================================

def retrieve_documents(question, top_k=3):
    """æ£€ç´¢æ–‡æ¡£"""
    q_vec = embedding_model.encode([question], show_progress_bar=False)
    results = collection.query(
        query_embeddings=q_vec.tolist(),
        n_results=top_k,
        include=["documents"]
    )
    return results['documents'][0]

# ============================================================
# ç¬¬ä¸€éƒ¨åˆ†ï¼šå¯¹æ¯”ä¸åŒPromptæ¨¡æ¿
# ============================================================

print("ã€ç¬¬ä¸€éƒ¨åˆ†ï¼šPromptæ¨¡æ¿å¯¹æ¯”ã€‘")
print("=" * 60)

question = "é…’é©¾çš„å¤„ç½šæ˜¯ä»€ä¹ˆï¼Ÿ"
docs = retrieve_documents(question, top_k=2)
context = "\n\n".join(docs)

print(f"\nâ“ æµ‹è¯•é—®é¢˜: {question}\n")

# Prompt 1: æç®€ç‰ˆï¼ˆå®¹æ˜“å‡ºé—®é¢˜ï¼‰
prompt1 = f"""{context}

é—®é¢˜ï¼š{question}
å›ç­”ï¼š"""

print("="*60)
print("Prompt 1: æç®€ç‰ˆ")
print("="*60)
print(prompt1[:200] + "...")

print("\nğŸ¤– ç”Ÿæˆç­”æ¡ˆ...")
output1 = llm(prompt1, max_tokens=150, temperature=0.3, stop=["\n\n"], echo=False, stream=False)
answer1 = output1['choices'][0]['text'].strip()
print(f"\nğŸ’¬ {answer1}")

print("\nâš ï¸  é—®é¢˜:")
print("   â€¢ æ²¡æœ‰è§’è‰²å®šä½")
print("   â€¢ æ²¡æœ‰æ˜ç¡®æŒ‡ä»¤")
print("   â€¢ å¯èƒ½åç¦»å‚è€ƒèµ„æ–™")

# Prompt 2: åŸºç¡€ç‰ˆ
prompt2 = f"""æ ¹æ®ä»¥ä¸‹å‚è€ƒèµ„æ–™å›ç­”é—®é¢˜ï¼š

ã€å‚è€ƒèµ„æ–™ã€‘
{context}

ã€é—®é¢˜ã€‘
{question}

ã€å›ç­”ã€‘
"""

print("\n" + "="*60)
print("Prompt 2: åŸºç¡€ç‰ˆ")
print("="*60)
print(prompt2[:200] + "...")

print("\nğŸ¤– ç”Ÿæˆç­”æ¡ˆ...")
output2 = llm(prompt2, max_tokens=150, temperature=0.3, stop=["ã€"], echo=False, stream=False)
answer2 = output2['choices'][0]['text'].strip()
print(f"\nğŸ’¬ {answer2}")

print("\nâœ… æ”¹è¿›:")
print("   â€¢ æ˜ç¡®äº†ã€Œå‚è€ƒèµ„æ–™ã€")
print("   â€¢ ç»“æ„æ¸…æ™°")

# Prompt 3: ä¸“ä¸šç‰ˆï¼ˆæ¨èï¼‰
prompt3 = f"""ä½ æ˜¯ä¸€ä¸ªäº¤é€šæ³•è§„åŠ©æ‰‹ï¼Œä¸“é—¨è§£ç­”ä¸­å›½é“è·¯äº¤é€šå®‰å…¨æ³•ç›¸å…³é—®é¢˜ã€‚

ã€å‚è€ƒèµ„æ–™ã€‘
{context}

ã€å›ç­”è¦æ±‚ã€‘
1. ä»…æ ¹æ®å‚è€ƒèµ„æ–™å›ç­”ï¼Œä¸è¦ç¼–é€ ä¿¡æ¯
2. å¦‚æœå‚è€ƒèµ„æ–™ä¸­æ²¡æœ‰ç­”æ¡ˆï¼Œè¯·æ˜ç¡®è¯´æ˜
3. å›ç­”è¦ç®€æ´å‡†ç¡®ï¼Œåˆ†ç‚¹åˆ—å‡ºè¦ç‚¹

ã€ç”¨æˆ·é—®é¢˜ã€‘
{question}

ã€ä½ çš„å›ç­”ã€‘
"""

print("\n" + "="*60)
print("Prompt 3: ä¸“ä¸šç‰ˆï¼ˆæ¨èï¼‰")
print("="*60)
print(prompt3[:250] + "...")

print("\nğŸ¤– ç”Ÿæˆç­”æ¡ˆ...")
output3 = llm(prompt3, max_tokens=200, temperature=0.3, stop=["ã€"], echo=False, stream=False)
answer3 = output3['choices'][0]['text'].strip()
print(f"\nğŸ’¬ {answer3}")

print("\nâœ… ä¼˜åŠ¿:")
print("   â€¢ æ˜ç¡®è§’è‰²å®šä½ï¼ˆäº¤é€šæ³•è§„åŠ©æ‰‹ï¼‰")
print("   â€¢ è¯¦ç»†çš„å›ç­”è¦æ±‚")
print("   â€¢ é˜²æ­¢ç¼–é€ ä¿¡æ¯")
print("   â€¢ æ ¼å¼è§„èŒƒ")

# ============================================================
# ç¬¬äºŒéƒ¨åˆ†ï¼šé˜²æ­¢å¹»è§‰ï¼ˆç¼–é€ ä¿¡æ¯ï¼‰
# ============================================================

print("\n\nã€ç¬¬äºŒéƒ¨åˆ†ï¼šé˜²æ­¢LLMå¹»è§‰ã€‘")
print("=" * 60)

# ç”¨ä¸€ä¸ªæ–‡æ¡£ä¸­æ²¡æœ‰çš„é—®é¢˜æµ‹è¯•
tricky_question = "é«˜é€Ÿå…¬è·¯æœ€ä½é™é€Ÿæ˜¯å¤šå°‘ï¼Ÿ"
print(f"\nâ“ æµ‹è¯•é—®é¢˜: {tricky_question}")
print("ï¼ˆæ³¨æ„ï¼šè¿™ä¸ªä¿¡æ¯å¯èƒ½ä¸åœ¨æˆ‘ä»¬çš„æ–‡æ¡£ä¸­ï¼‰\n")

docs_tricky = retrieve_documents(tricky_question, top_k=2)
context_tricky = "\n\n".join(docs_tricky)

# ä¸é˜²å¹»è§‰çš„Prompt
prompt_no_guard = f"""æ ¹æ®å‚è€ƒèµ„æ–™å›ç­”ï¼š

{context_tricky}

é—®é¢˜ï¼š{tricky_question}
å›ç­”ï¼š"""

print("="*60)
print("ä¸é˜²å¹»è§‰çš„Prompt")
print("="*60)

output_no_guard = llm(prompt_no_guard, max_tokens=100, temperature=0.5, stop=["\n\n"], echo=False, stream=False)
answer_no_guard = output_no_guard['choices'][0]['text'].strip()
print(f"\nğŸ’¬ {answer_no_guard}")

print("\nâš ï¸  é£é™©: LLMå¯èƒ½åŸºäºè®°å¿†å›ç­”ï¼Œè€Œä¸æ˜¯å‚è€ƒèµ„æ–™")

# é˜²å¹»è§‰çš„Prompt
prompt_with_guard = f"""ä½ æ˜¯ä¸€ä¸ªä¸¥è°¨çš„äº¤é€šæ³•è§„åŠ©æ‰‹ã€‚

ã€å‚è€ƒèµ„æ–™ã€‘
{context_tricky}

ã€é‡è¦è§„åˆ™ã€‘
- ä»…æ ¹æ®å‚è€ƒèµ„æ–™å›ç­”
- å¦‚æœå‚è€ƒèµ„æ–™ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·å›ç­”ï¼šã€Œå‚è€ƒèµ„æ–™ä¸­æœªæåŠæ­¤å†…å®¹ã€
- ç»å¯¹ä¸è¦ç¼–é€ æˆ–çŒœæµ‹ç­”æ¡ˆ

ã€é—®é¢˜ã€‘
{tricky_question}

ã€å›ç­”ã€‘
"""

print("\n" + "="*60)
print("é˜²å¹»è§‰çš„Prompt")
print("="*60)

output_with_guard = llm(prompt_with_guard, max_tokens=100, temperature=0.2, stop=["ã€"], echo=False, stream=False)
answer_with_guard = output_with_guard['choices'][0]['text'].strip()
print(f"\nğŸ’¬ {answer_with_guard}")

print("\nâœ… é˜²å¹»è§‰ç­–ç•¥:")
print("   1. æ˜ç¡®è¯´æ˜ã€Œä»…æ ¹æ®å‚è€ƒèµ„æ–™ã€")
print("   2. æä¾›ã€ŒæœªæåŠã€çš„æ ‡å‡†å›ç­”")
print("   3. é™ä½temperatureï¼ˆ0.1-0.3ï¼‰")
print("   4. å¼ºè°ƒã€Œä¸è¦ç¼–é€ ã€")

# ============================================================
# ç¬¬ä¸‰éƒ¨åˆ†ï¼šå¸¦å¼•ç”¨çš„å›ç­”
# ============================================================

print("\n\nã€ç¬¬ä¸‰éƒ¨åˆ†ï¼šå¸¦å¼•ç”¨çš„å›ç­”ã€‘")
print("=" * 60)

question_cite = "é©¾é©¶è¯æ‰£12åˆ†åæ€ä¹ˆåŠï¼Ÿ"
print(f"\nâ“ é—®é¢˜: {question_cite}\n")

docs_cite = retrieve_documents(question_cite, top_k=3)

# æ„å»ºå¸¦ç¼–å·çš„å‚è€ƒèµ„æ–™
context_with_numbers = ""
for i, doc in enumerate(docs_cite, 1):
    context_with_numbers += f"[æ–‡æ¡£{i}]\n{doc}\n\n"

prompt_with_citation = f"""ä½ æ˜¯ä¸€ä¸ªäº¤é€šæ³•è§„åŠ©æ‰‹ã€‚è¯·æ ¹æ®å‚è€ƒèµ„æ–™å›ç­”é—®é¢˜ï¼Œå¹¶ç”¨[æ–‡æ¡£X]æ ‡æ³¨å¼•ç”¨æ¥æºã€‚

ã€å‚è€ƒèµ„æ–™ã€‘
{context_with_numbers}

ã€å›ç­”è¦æ±‚ã€‘
1. åœ¨å›ç­”ä¸­ç”¨[æ–‡æ¡£1]ã€[æ–‡æ¡£2]ç­‰æ ‡æ³¨å¼•ç”¨æ¥æº
2. åªä½¿ç”¨å‚è€ƒèµ„æ–™ä¸­çš„ä¿¡æ¯
3. åˆ†ç‚¹å›ç­”ï¼Œæ¯ç‚¹åé¢æ ‡æ³¨æ¥æº

ã€é—®é¢˜ã€‘
{question_cite}

ã€å›ç­”ã€‘ï¼ˆè¯·åœ¨æ¯ä¸ªè¦ç‚¹åæ ‡æ³¨[æ–‡æ¡£X]ï¼‰
"""

print("ğŸ¤– ç”Ÿæˆå¸¦å¼•ç”¨çš„ç­”æ¡ˆ...")
output_cite = llm(prompt_with_citation, max_tokens=300, temperature=0.3, stop=["ã€"], echo=False, stream=False)
answer_cite = output_cite['choices'][0]['text'].strip()

print(f"\nğŸ’¬ {answer_cite}")

print("\nâœ… å¸¦å¼•ç”¨çš„ä¼˜åŠ¿:")
print("   â€¢ ç”¨æˆ·å¯ä»¥éªŒè¯ç­”æ¡ˆæ¥æº")
print("   â€¢ æé«˜å¯ä¿¡åº¦")
print("   â€¢ ä¾¿äºè¿½æº¯åŸæ–‡")
print("   â€¢ ä¸“ä¸šæ€§å¼º")

# ============================================================
# ç¬¬å››éƒ¨åˆ†ï¼šæ§åˆ¶å›ç­”é•¿åº¦å’Œæ ¼å¼
# ============================================================

print("\n\nã€ç¬¬å››éƒ¨åˆ†ï¼šæ§åˆ¶å›ç­”æ ¼å¼ã€‘")
print("=" * 60)

question_format = "é—¯çº¢ç¯çš„å¤„ç½šæ˜¯ä»€ä¹ˆï¼Ÿ"
docs_format = retrieve_documents(question_format, top_k=2)
context_format = "\n\n".join(docs_format)

# æ ¼å¼1ï¼šç®€æ´ç‰ˆ
prompt_short = f"""ä½ æ˜¯äº¤é€šæ³•è§„åŠ©æ‰‹ï¼Œç”¨æœ€ç®€æ´çš„æ–¹å¼å›ç­”ã€‚

å‚è€ƒèµ„æ–™ï¼š
{context_format}

è¦æ±‚ï¼šä¸€å¥è¯å›ç­”ï¼Œä¸è¶…è¿‡30å­—ã€‚

é—®é¢˜ï¼š{question_format}
å›ç­”ï¼š"""

print(f"\nâ“ é—®é¢˜: {question_format}")
print("\n" + "="*60)
print("æ ¼å¼1: è¶…ç®€æ´ï¼ˆä¸€å¥è¯ï¼Œ30å­—å†…ï¼‰")
print("="*60)

output_short = llm(prompt_short, max_tokens=50, temperature=0.2, stop=["\n"], echo=False, stream=False)
answer_short = output_short['choices'][0]['text'].strip()
print(f"\nğŸ’¬ {answer_short}")
print(f"   ï¼ˆ{len(answer_short)}å­—ï¼‰")

# æ ¼å¼2ï¼šåˆ†ç‚¹åˆ—å‡º
prompt_points = f"""ä½ æ˜¯äº¤é€šæ³•è§„åŠ©æ‰‹ï¼Œè¯·åˆ†ç‚¹å›ç­”ã€‚

å‚è€ƒèµ„æ–™ï¼š
{context_format}

è¦æ±‚ï¼šåˆ†3ç‚¹å›ç­”ï¼Œæ¯ç‚¹ä¸€å¥è¯ã€‚

é—®é¢˜ï¼š{question_format}
å›ç­”ï¼š"""

print("\n" + "="*60)
print("æ ¼å¼2: åˆ†ç‚¹åˆ—å‡ºï¼ˆ3ç‚¹ï¼‰")
print("="*60)

output_points = llm(prompt_points, max_tokens=150, temperature=0.2, stop=["\n\n"], echo=False, stream=False)
answer_points = output_points['choices'][0]['text'].strip()
print(f"\nğŸ’¬ {answer_points}")

print("\nğŸ’¡ æ ¼å¼æ§åˆ¶æŠ€å·§:")
print("   â€¢ åœ¨Promptä¸­æ˜ç¡®è¦æ±‚é•¿åº¦")
print("   â€¢ æŒ‡å®šå›ç­”æ ¼å¼ï¼ˆåˆ†ç‚¹/è¡¨æ ¼/ä¸€å¥è¯ï¼‰")
print("   â€¢ ä½¿ç”¨max_tokensé™åˆ¶")
print("   â€¢ è°ƒæ•´stopæ ‡è®°")

# ============================================================
# ç¬¬äº”éƒ¨åˆ†ï¼šæœ€ä½³Promptæ¨¡æ¿æ€»ç»“
# ============================================================

print("\n\nã€ç¬¬äº”éƒ¨åˆ†ï¼šæœ€ä½³Promptæ¨¡æ¿ã€‘")
print("=" * 60)

best_prompt_template = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„äº¤é€šæ³•è§„åŠ©æ‰‹ï¼Œä¸“é—¨è§£ç­”ä¸­å›½é“è·¯äº¤é€šå®‰å…¨æ³•ç›¸å…³é—®é¢˜ã€‚

ã€å‚è€ƒèµ„æ–™ã€‘
{context}

ã€å›ç­”è§„åˆ™ã€‘
1. ä¸¥æ ¼ä¾æ®å‚è€ƒèµ„æ–™å›ç­”ï¼Œä¸ç¼–é€ ä¿¡æ¯
2. å¦‚æœå‚è€ƒèµ„æ–™ä¸­æ²¡æœ‰ç›¸å…³å†…å®¹ï¼Œæ˜ç¡®å›ç­”ã€Œå‚è€ƒèµ„æ–™ä¸­æœªæåŠæ­¤å†…å®¹ã€
3. å›ç­”è¦å‡†ç¡®ã€ç®€æ´ã€åˆ†ç‚¹åˆ—å‡º
4. ä¿æŒå®¢è§‚ä¸­ç«‹çš„è¯­æ°”

ã€ç”¨æˆ·é—®é¢˜ã€‘
{question}

ã€ä½ çš„å›ç­”ã€‘
"""

print("\nâœ… æœ€ä½³æ¨¡æ¿è¦ç´ :")
print("   1. ğŸ­ è§’è‰²å®šä½: ã€Œä½ æ˜¯XXåŠ©æ‰‹ã€")
print("   2. ğŸ“š èµ„æ–™æ ‡æ³¨: æ¸…æ™°çš„ã€å‚è€ƒèµ„æ–™ã€‘æ ‡ç­¾")
print("   3. ğŸ“‹ å›ç­”è§„åˆ™: è¯¦ç»†çš„çº¦æŸæ¡ä»¶")
print("   4. ğŸš« é˜²å¹»è§‰: ã€Œä¸ç¼–é€ ã€ã€ŒæœªæåŠã€")
print("   5. ğŸ“ æ ¼å¼è¦æ±‚: ã€Œåˆ†ç‚¹ã€ã€Œç®€æ´ã€")

print("\nğŸ’¡ å…³é”®å‚æ•°:")
print("   â€¢ temperature = 0.1-0.3ï¼ˆä½æ¸©åº¦ï¼Œæ›´ç¡®å®šï¼‰")
print("   â€¢ max_tokens = 200-400ï¼ˆæ§åˆ¶é•¿åº¦ï¼‰")
print("   â€¢ stop = [\"ã€\", \"\\n\\n\"]ï¼ˆåœæ­¢æ ‡è®°ï¼‰")

# ============================================================
# æ€»ç»“
# ============================================================

print("\n\n" + "=" * 60)
print("ğŸ‰ Promptä¼˜åŒ–å­¦ä¹ å®Œæˆï¼")
print("=" * 60)

print("\nâœ… æŒæ¡çš„æŠ€å·§:")
print("   1. å¯¹æ¯”ä¸åŒPromptæ•ˆæœ")
print("   2. é˜²æ­¢LLMå¹»è§‰")
print("   3. å¸¦å¼•ç”¨çš„å›ç­”")
print("   4. æ§åˆ¶å›ç­”æ ¼å¼å’Œé•¿åº¦")
print("   5. æœ€ä½³Promptæ¨¡æ¿")

print("\nğŸ’¡ æ ¸å¿ƒåŸåˆ™:")
print("   â€¢ æ˜ç¡®è§’è‰²å’Œä»»åŠ¡")
print("   â€¢ è¯¦ç»†çš„å›ç­”è§„åˆ™")
print("   â€¢ é˜²æ­¢ç¼–é€ ä¿¡æ¯")
print("   â€¢ æ ¼å¼åŒ–è¾“å‡º")

print("\nğŸ¯ ä¸‹ä¸€æ­¥:")
print("   è¿è¡Œ: python 04_complete_rag_system.py")
print("   æ•´åˆæ‰€æœ‰ä¼˜åŒ–ï¼Œæ„å»ºå®Œæ•´RAGç³»ç»Ÿ")

print("\n" + "=" * 60)

