#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Step 4.3: é«˜çº§æ£€ç´¢æŠ€å·§
å­¦ä¹ ç›®æ ‡ï¼šæŒæ¡å¤æ‚æŸ¥è¯¢å’Œç»“æœä¼˜åŒ–
"""

import chromadb
from sentence_transformers import SentenceTransformer
import numpy as np
import json

print("=" * 60)
print("ğŸ” ChromaDBé«˜çº§æ£€ç´¢æŠ€å·§")
print("=" * 60)

# ============================================================
# ç¬¬ä¸€éƒ¨åˆ†ï¼šè¿æ¥æ•°æ®åº“
# ============================================================

print("\nã€ç¬¬ä¸€éƒ¨åˆ†ï¼šè¿æ¥æ•°æ®åº“ã€‘")
print("-" * 60)

# è¿æ¥åˆ°å·²æœ‰çš„æ•°æ®åº“
db_path = "./data/chroma_traffic_law"
client = chromadb.PersistentClient(path=db_path)
collection = client.get_collection(name="traffic_law")

count = collection.count()
print(f"âœ… è¿æ¥æˆåŠŸ")
print(f"ğŸ“Š æ•°æ®åº“åŒ…å« {count} ä¸ªæ–‡æ¡£")

# åŠ è½½æ¨¡å‹
print(f"\nğŸ“¦ åŠ è½½embeddingæ¨¡å‹...")
model = SentenceTransformer('shibing624/text2vec-base-chinese')
print("   âœ… æ¨¡å‹åŠ è½½å®Œæˆ")

# ============================================================
# ç¬¬äºŒéƒ¨åˆ†ï¼šåŸºç¡€æ£€ç´¢å›é¡¾
# ============================================================

print("\nã€ç¬¬äºŒéƒ¨åˆ†ï¼šåŸºç¡€æ£€ç´¢ã€‘")
print("-" * 60)

question = "é…’é©¾çš„å¤„ç½šæ˜¯ä»€ä¹ˆï¼Ÿ"
print(f"\nâ“ é—®é¢˜: {question}")

# ç”Ÿæˆå‘é‡
query_embedding = model.encode([question], show_progress_bar=False)

# åŸºç¡€æ£€ç´¢ï¼ˆTop-3ï¼‰
results = collection.query(
    query_embeddings=query_embedding.tolist(),
    n_results=3,
    include=["documents", "metadatas", "distances"]
)

print("\nğŸ” åŸºç¡€æ£€ç´¢ç»“æœ:")
for i in range(len(results['ids'][0])):
    document = results['documents'][0][i]
    distance = results['distances'][0][i]
    similarity = 1 - distance
    
    print(f"\n[Top-{i+1}] ç›¸ä¼¼åº¦: {similarity*100:.1f}%")
    preview = document[:80] + "..." if len(document) > 80 else document
    print(f"   {preview}")

# ============================================================
# ç¬¬ä¸‰éƒ¨åˆ†ï¼šå…ƒæ•°æ®è¿‡æ»¤ï¼ˆWhereå­å¥ï¼‰
# ============================================================

print("\nã€ç¬¬ä¸‰éƒ¨åˆ†ï¼šå…ƒæ•°æ®è¿‡æ»¤ã€‘")
print("-" * 60)

# åœºæ™¯1ï¼šæŒ‰ç« èŠ‚è¿‡æ»¤
print("\nğŸ”¹ åœºæ™¯1: åªæœç´¢ã€Œç¬¬äº”ç« ã€")
question1 = "äº¤é€šäº‹æ•…å¦‚ä½•å¤„ç†ï¼Ÿ"
print(f"   é—®é¢˜: {question1}")

query_embedding1 = model.encode([question1], show_progress_bar=False)

results1 = collection.query(
    query_embeddings=query_embedding1.tolist(),
    n_results=2,
    where={"chapter": "ç¬¬äº”ç« "},  # åªæœç´¢ç¬¬äº”ç« 
    include=["documents", "metadatas", "distances"]
)

print(f"\n   ç»“æœ:")
for i in range(len(results1['ids'][0])):
    chapter = results1['metadatas'][0][i]['chapter']
    document = results1['documents'][0][i]
    similarity = 1 - results1['distances'][0][i]
    
    print(f"   [{i+1}] {chapter} | ç›¸ä¼¼åº¦: {similarity*100:.1f}%")
    preview = document[:60] + "..." if len(document) > 60 else document
    print(f"       {preview}")

# åœºæ™¯2ï¼šæŒ‰é•¿åº¦è¿‡æ»¤ï¼ˆæ‰¾é•¿æ–‡æœ¬ï¼‰
print("\nğŸ”¹ åœºæ™¯2: åªæœç´¢é•¿åº¦>350çš„æ–‡æœ¬å—")
question2 = "é©¾é©¶è¯æ‰£åˆ†åˆ¶åº¦"
print(f"   é—®é¢˜: {question2}")

query_embedding2 = model.encode([question2], show_progress_bar=False)

results2 = collection.query(
    query_embeddings=query_embedding2.tolist(),
    n_results=2,
    where={"length": {"$gt": 350}},  # é•¿åº¦å¤§äº350
    include=["documents", "metadatas", "distances"]
)

print(f"\n   ç»“æœ:")
for i in range(len(results2['ids'][0])):
    length = results2['metadatas'][0][i]['length']
    document = results2['documents'][0][i]
    similarity = 1 - results2['distances'][0][i]
    
    print(f"   [{i+1}] é•¿åº¦: {length} | ç›¸ä¼¼åº¦: {similarity*100:.1f}%")
    preview = document[:60] + "..." if len(document) > 60 else document
    print(f"       {preview}")

# åœºæ™¯3ï¼šå¤åˆæ¡ä»¶ï¼ˆANDé€»è¾‘ï¼‰
print("\nğŸ”¹ åœºæ™¯3: ç¬¬ä¸‰ç«  AND é•¿åº¦>300")
question3 = "æ‰£åˆ†è§„åˆ™"
print(f"   é—®é¢˜: {question3}")

query_embedding3 = model.encode([question3], show_progress_bar=False)

results3 = collection.query(
    query_embeddings=query_embedding3.tolist(),
    n_results=2,
    where={
        "$and": [
            {"chapter": "ç¬¬ä¸‰ç« "},
            {"length": {"$gt": 300}}
        ]
    },
    include=["documents", "metadatas", "distances"]
)

if len(results3['ids'][0]) > 0:
    print(f"\n   ç»“æœ:")
    for i in range(len(results3['ids'][0])):
        chapter = results3['metadatas'][0][i]['chapter']
        length = results3['metadatas'][0][i]['length']
        document = results3['documents'][0][i]
        similarity = 1 - results3['distances'][0][i]
        
        print(f"   [{i+1}] {chapter}, {length}å­— | ç›¸ä¼¼åº¦: {similarity*100:.1f}%")
        preview = document[:60] + "..." if len(document) > 60 else document
        print(f"       {preview}")
else:
    print("   âš ï¸  æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ–‡æ¡£")

# ============================================================
# ç¬¬å››éƒ¨åˆ†ï¼šè°ƒæ•´è¿”å›æ•°é‡ï¼ˆTop-Kï¼‰
# ============================================================

print("\nã€ç¬¬å››éƒ¨åˆ†ï¼šè°ƒæ•´Top-Kã€‘")
print("-" * 60)

question = "è¶…é€Ÿæ€ä¹ˆå¤„ç½šï¼Ÿ"
print(f"\nâ“ é—®é¢˜: {question}")

query_embedding = model.encode([question], show_progress_bar=False)

# æµ‹è¯•ä¸åŒçš„Kå€¼
k_values = [1, 3, 5]

for k in k_values:
    results = collection.query(
        query_embeddings=query_embedding.tolist(),
        n_results=k,
        include=["documents", "distances"]
    )
    
    print(f"\nğŸ“Š Top-{k} ç»“æœ:")
    for i in range(len(results['ids'][0])):
        similarity = 1 - results['distances'][0][i]
        print(f"   [{i+1}] ç›¸ä¼¼åº¦: {similarity*100:.1f}%")

# ============================================================
# ç¬¬äº”éƒ¨åˆ†ï¼šç›¸ä¼¼åº¦é˜ˆå€¼è¿‡æ»¤
# ============================================================

print("\nã€ç¬¬äº”éƒ¨åˆ†ï¼šç›¸ä¼¼åº¦é˜ˆå€¼è¿‡æ»¤ã€‘")
print("-" * 60)

question = "åœè½¦è§„å®š"
print(f"\nâ“ é—®é¢˜: {question}")

query_embedding = model.encode([question], show_progress_bar=False)

# è·å–Top-10
results = collection.query(
    query_embeddings=query_embedding.tolist(),
    n_results=10,
    include=["documents", "distances"]
)

# åªä¿ç•™ç›¸ä¼¼åº¦>70%çš„ç»“æœ
threshold = 0.70
print(f"\nğŸ¯ è¿‡æ»¤æ¡ä»¶: ç›¸ä¼¼åº¦ > {threshold*100}%")

filtered_results = []
for i in range(len(results['ids'][0])):
    distance = results['distances'][0][i]
    similarity = 1 - distance
    
    if similarity > threshold:
        filtered_results.append({
            'document': results['documents'][0][i],
            'similarity': similarity
        })

print(f"\nâœ… æ‰¾åˆ° {len(filtered_results)} ä¸ªé«˜è´¨é‡ç»“æœ:")
for i, result in enumerate(filtered_results, 1):
    print(f"\n[{i}] ç›¸ä¼¼åº¦: {result['similarity']*100:.1f}%")
    preview = result['document'][:80] + "..." if len(result['document']) > 80 else result['document']
    print(f"    {preview}")

if len(filtered_results) == 0:
    print("   âš ï¸  æ²¡æœ‰æ‰¾åˆ°ç›¸ä¼¼åº¦è¶…è¿‡é˜ˆå€¼çš„ç»“æœ")
    print("   ğŸ’¡ å»ºè®®ï¼šé™ä½é˜ˆå€¼æˆ–æ”¹å†™é—®é¢˜")

# ============================================================
# ç¬¬å…­éƒ¨åˆ†ï¼šå¤šé—®é¢˜æ‰¹é‡æ£€ç´¢
# ============================================================

print("\nã€ç¬¬å…­éƒ¨åˆ†ï¼šæ‰¹é‡æ£€ç´¢ã€‘")
print("-" * 60)

questions = [
    "é—¯çº¢ç¯æ‰£åˆ†",
    "é…’é©¾å¤„ç½š",
    "è¶…é€Ÿç½šæ¬¾"
]

print(f"\nğŸ“ æ‰¹é‡æ£€ç´¢ {len(questions)} ä¸ªé—®é¢˜...")

# æ‰¹é‡ç”Ÿæˆå‘é‡
query_embeddings = model.encode(questions, show_progress_bar=False)

# æ‰¹é‡æŸ¥è¯¢
results = collection.query(
    query_embeddings=query_embeddings.tolist(),
    n_results=2,
    include=["documents", "distances"]
)

# æ˜¾ç¤ºç»“æœ
for i, question in enumerate(questions):
    print(f"\nã€é—®é¢˜ {i+1}ã€‘{question}")
    
    for j in range(len(results['ids'][i])):
        similarity = 1 - results['distances'][i][j]
        document = results['documents'][i][j]
        
        print(f"  [Top-{j+1}] ç›¸ä¼¼åº¦: {similarity*100:.1f}%")
        preview = document[:60] + "..." if len(document) > 60 else document
        print(f"          {preview}")

# ============================================================
# ç¬¬ä¸ƒéƒ¨åˆ†ï¼šç»“æœå»é‡
# ============================================================

print("\nã€ç¬¬ä¸ƒéƒ¨åˆ†ï¼šç»“æœå»é‡ã€‘")
print("-" * 60)

# ç›¸ä¼¼é—®é¢˜å¯èƒ½æ£€ç´¢åˆ°ç›¸åŒçš„æ–‡æ¡£
questions = [
    "é…’åé©¾é©¶çš„å¤„ç½š",
    "é†‰é©¾ä¼šå—åˆ°ä»€ä¹ˆæƒ©ç½š"
]

print(f"\nğŸ“ æ£€ç´¢ç›¸ä¼¼é—®é¢˜:")
for q in questions:
    print(f"   â€¢ {q}")

all_doc_ids = set()
all_results = []

for question in questions:
    query_embedding = model.encode([question], show_progress_bar=False)
    
    results = collection.query(
        query_embeddings=query_embedding.tolist(),
        n_results=3,
        include=["documents", "distances"]
    )
    
    for i in range(len(results['ids'][0])):
        doc_id = results['ids'][0][i]
        
        # å»é‡
        if doc_id not in all_doc_ids:
            all_doc_ids.add(doc_id)
            all_results.append({
                'id': doc_id,
                'document': results['documents'][0][i],
                'similarity': 1 - results['distances'][0][i]
            })

print(f"\nâœ… å»é‡åçš„ç»“æœ (å…±{len(all_results)}ä¸ª):")
for i, result in enumerate(all_results, 1):
    print(f"\n[{i}] ID: {result['id']} | ç›¸ä¼¼åº¦: {result['similarity']*100:.1f}%")
    preview = result['document'][:70] + "..." if len(result['document']) > 70 else result['document']
    print(f"    {preview}")

# ============================================================
# ç¬¬å…«éƒ¨åˆ†ï¼šæ£€ç´¢æ€§èƒ½æµ‹è¯•
# ============================================================

print("\nã€ç¬¬å…«éƒ¨åˆ†ï¼šæ€§èƒ½æµ‹è¯•ã€‘")
print("-" * 60)

import time

# æµ‹è¯•ä¸åŒTop-Kçš„é€Ÿåº¦
print(f"\nâ±ï¸  æµ‹è¯•æ£€ç´¢é€Ÿåº¦ï¼ˆ10æ¬¡å¹³å‡ï¼‰...")

question = "äº¤é€šè¿æ³•å¤„ç½šæ ‡å‡†"
query_embedding = model.encode([question], show_progress_bar=False)

for k in [1, 5, 10, 20]:
    times = []
    
    for _ in range(10):
        start = time.time()
        results = collection.query(
            query_embeddings=query_embedding.tolist(),
            n_results=k,
            include=["distances"]
        )
        end = time.time()
        times.append((end - start) * 1000)  # è½¬ä¸ºæ¯«ç§’
    
    avg_time = np.mean(times)
    print(f"   Top-{k:2d}: {avg_time:.2f}ms")

# ============================================================
# æ€»ç»“
# ============================================================

print("\n" + "=" * 60)
print("ğŸ‰ é«˜çº§æ£€ç´¢æŠ€å·§å­¦ä¹ å®Œæˆï¼")
print("=" * 60)

print("\nâœ… æŒæ¡çš„æŠ€èƒ½:")
print("   1. åŸºç¡€è¯­ä¹‰æ£€ç´¢")
print("   2. å…ƒæ•°æ®è¿‡æ»¤ï¼ˆwhereå­å¥ï¼‰")
print("   3. å¤åˆæ¡ä»¶æŸ¥è¯¢ï¼ˆ$and, $gtç­‰ï¼‰")
print("   4. Top-Kè°ƒæ•´")
print("   5. ç›¸ä¼¼åº¦é˜ˆå€¼è¿‡æ»¤")
print("   6. æ‰¹é‡æ£€ç´¢")
print("   7. ç»“æœå»é‡")
print("   8. æ€§èƒ½æµ‹è¯•")

print("\nğŸ’¡ å®ç”¨æŠ€å·§:")
print("   â€¢ å…ˆç”¨é«˜Top-Kæ£€ç´¢ï¼Œå†ç”¨é˜ˆå€¼è¿‡æ»¤")
print("   â€¢ ç»“åˆå…ƒæ•°æ®ç¼©å°æœç´¢èŒƒå›´")
print("   â€¢ æ‰¹é‡æ£€ç´¢æé«˜æ•ˆç‡")
print("   â€¢ å»é‡é¿å…é‡å¤å†…å®¹")

print("\nğŸ¯ ä¸‹ä¸€æ­¥:")
print("   è¿è¡Œ: python 04_performance.py")
print("   å­¦ä¹ æ€§èƒ½ä¼˜åŒ–æŠ€å·§")

print("\n" + "=" * 60)

