#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Step 4.4: æ€§èƒ½ä¼˜åŒ–
å­¦ä¹ ç›®æ ‡ï¼šä¼˜åŒ–å‘é‡æ•°æ®åº“çš„å¯¼å…¥å’Œæ£€ç´¢æ€§èƒ½
"""

import chromadb
from sentence_transformers import SentenceTransformer
import numpy as np
import time
import os

print("=" * 60)
print("âš¡ ChromaDBæ€§èƒ½ä¼˜åŒ–")
print("=" * 60)

# ============================================================
# ç¬¬ä¸€éƒ¨åˆ†ï¼šæ‰¹é‡å¯¼å…¥æ€§èƒ½æµ‹è¯•
# ============================================================

print("\nã€ç¬¬ä¸€éƒ¨åˆ†ï¼šæ‰¹é‡å¯¼å…¥æ€§èƒ½æµ‹è¯•ã€‘")
print("-" * 60)

# åŠ è½½æ¨¡å‹
print(f"\nğŸ“¦ åŠ è½½embeddingæ¨¡å‹...")
model = SentenceTransformer('shibing624/text2vec-base-chinese')
print("   âœ… æ¨¡å‹åŠ è½½å®Œæˆ")

# å‡†å¤‡æµ‹è¯•æ•°æ®ï¼ˆ100ä¸ªæ–‡æ¡£ï¼‰
num_docs = 100
test_docs = [f"è¿™æ˜¯ç¬¬{i}ä¸ªæµ‹è¯•æ–‡æ¡£ï¼Œå†…å®¹å…³äºäº¤é€šæ³•è§„å’Œé©¾é©¶å®‰å…¨" for i in range(num_docs)]

print(f"\nğŸ”„ ç”Ÿæˆ {num_docs} ä¸ªæµ‹è¯•å‘é‡...")
test_embeddings = model.encode(test_docs, show_progress_bar=False)
print(f"   âœ… å‘é‡ç”Ÿæˆå®Œæˆ: {test_embeddings.shape}")

# åˆ›å»ºä¸´æ—¶æ•°æ®åº“
db_path = "./data/chroma_performance_test"
os.makedirs(db_path, exist_ok=True)
client = chromadb.PersistentClient(path=db_path)

# æµ‹è¯•ä¸åŒçš„æ‰¹é‡å¤§å°
batch_sizes = [1, 10, 25, 50, 100]

print(f"\nâ±ï¸  æµ‹è¯•ä¸åŒæ‰¹é‡å¤§å°çš„å¯¼å…¥é€Ÿåº¦:")
print("-" * 60)

results = []

for batch_size in batch_sizes:
    # åˆ é™¤æ—§é›†åˆ
    try:
        client.delete_collection(name=f"test_batch_{batch_size}")
    except:
        pass
    
    # åˆ›å»ºæ–°é›†åˆ
    collection = client.create_collection(name=f"test_batch_{batch_size}")
    
    # å¼€å§‹è®¡æ—¶
    start_time = time.time()
    
    # æ‰¹é‡å¯¼å…¥
    for i in range(0, num_docs, batch_size):
        end_idx = min(i + batch_size, num_docs)
        batch_embeddings = test_embeddings[i:end_idx].tolist()
        batch_docs = test_docs[i:end_idx]
        batch_ids = [f"doc_{j}" for j in range(i, end_idx)]
        
        collection.add(
            embeddings=batch_embeddings,
            documents=batch_docs,
            ids=batch_ids
        )
    
    # ç»“æŸè®¡æ—¶
    end_time = time.time()
    elapsed = (end_time - start_time) * 1000  # è½¬ä¸ºæ¯«ç§’
    
    results.append({
        'batch_size': batch_size,
        'time': elapsed,
        'docs_per_sec': num_docs / (elapsed / 1000)
    })
    
    print(f"   æ‰¹é‡å¤§å° {batch_size:3d}: {elapsed:6.2f}ms ({results[-1]['docs_per_sec']:.1f} docs/s)")

# æœ€ä½³æ‰¹é‡å¤§å°
best = min(results, key=lambda x: x['time'])
print(f"\nâœ… æœ€ä½³æ‰¹é‡å¤§å°: {best['batch_size']} (é€Ÿåº¦: {best['docs_per_sec']:.1f} docs/s)")

# ============================================================
# ç¬¬äºŒéƒ¨åˆ†ï¼šæ£€ç´¢æ€§èƒ½æµ‹è¯•
# ============================================================

print("\nã€ç¬¬äºŒéƒ¨åˆ†ï¼šæ£€ç´¢æ€§èƒ½æµ‹è¯•ã€‘")
print("-" * 60)

# ä½¿ç”¨çœŸå®æ•°æ®åº“
real_db_path = "./data/chroma_traffic_law"
if not os.path.exists(real_db_path):
    print("\nâš ï¸  è¯·å…ˆè¿è¡Œ 02_import_traffic_law.py åˆ›å»ºæ•°æ®åº“")
else:
    real_client = chromadb.PersistentClient(path=real_db_path)
    real_collection = real_client.get_collection(name="traffic_law")
    
    print(f"\nğŸ“Š æ•°æ®åº“è§„æ¨¡: {real_collection.count()} ä¸ªæ–‡æ¡£")
    
    # æµ‹è¯•é—®é¢˜
    test_questions = [
        "é…’é©¾å¤„ç½šæ ‡å‡†",
        "é—¯çº¢ç¯æ‰£åˆ†",
        "è¶…é€Ÿç½šæ¬¾é‡‘é¢",
        "äº¤é€šäº‹æ•…å¤„ç†",
        "é©¾é©¶è¯æ‰£åˆ†"
    ]
    
    print(f"\nâ±ï¸  æµ‹è¯•æ£€ç´¢é€Ÿåº¦ï¼ˆæ¯ä¸ªé—®é¢˜è¿è¡Œ10æ¬¡ï¼‰:")
    print("-" * 60)
    
    for k in [1, 5, 10, 20]:
        all_times = []
        
        for question in test_questions:
            query_embedding = model.encode([question], show_progress_bar=False)
            
            # è¿è¡Œ10æ¬¡å–å¹³å‡
            times = []
            for _ in range(10):
                start = time.time()
                results = real_collection.query(
                    query_embeddings=query_embedding.tolist(),
                    n_results=k,
                    include=["distances"]
                )
                end = time.time()
                times.append((end - start) * 1000)
            
            all_times.extend(times)
        
        avg_time = np.mean(all_times)
        std_time = np.std(all_times)
        
        print(f"   Top-{k:2d}: {avg_time:5.2f}ms Â± {std_time:4.2f}ms")
    
    print("\nğŸ’¡ è§‚å¯Ÿ:")
    print("   â€¢ æ£€ç´¢é€Ÿåº¦ä¸Top-Kå…³ç³»ä¸å¤§")
    print("   â€¢ ChromaDBçš„ANNç®—æ³•ä¼˜åŒ–äº†æœç´¢")
    print("   â€¢ å³ä½¿Top-20ä¹Ÿåªéœ€å‡ æ¯«ç§’")

# ============================================================
# ç¬¬ä¸‰éƒ¨åˆ†ï¼šå†…å­˜ä½¿ç”¨åˆ†æ
# ============================================================

print("\nã€ç¬¬ä¸‰éƒ¨åˆ†ï¼šå†…å­˜ä½¿ç”¨åˆ†æã€‘")
print("-" * 60)

import psutil
import gc

# è·å–å½“å‰è¿›ç¨‹
process = psutil.Process(os.getpid())

# åˆå§‹å†…å­˜
gc.collect()
mem_before = process.memory_info().rss / 1024 / 1024  # MB

print(f"\nğŸ’¾ åˆå§‹å†…å­˜: {mem_before:.1f} MB")

# åŠ è½½å¤§é‡æ•°æ®
print(f"\nğŸ”„ åˆ›å»ºå¤§è§„æ¨¡æµ‹è¯•æ•°æ®...")
large_num = 1000
large_docs = [f"æµ‹è¯•æ–‡æ¡£{i}" * 10 for i in range(large_num)]  # æ¯ä¸ªæ–‡æ¡£çº¦100å­—ç¬¦
large_embeddings = model.encode(large_docs, show_progress_bar=True, batch_size=64)

# æµ‹é‡å†…å­˜å¢é•¿
gc.collect()
mem_after = process.memory_info().rss / 1024 / 1024  # MB

print(f"\nğŸ’¾ ç”Ÿæˆå‘é‡åçš„å†…å­˜: {mem_after:.1f} MB")
print(f"ğŸ“ˆ å†…å­˜å¢é•¿: {mem_after - mem_before:.1f} MB")

# è®¡ç®—å‘é‡å ç”¨çš„ç†è®ºå†…å­˜
# 768ç»´ * 4å­—èŠ‚(float32) * 1000ä¸ªå‘é‡
vector_size_mb = (768 * 4 * large_num) / 1024 / 1024
print(f"\nğŸ“Š å‘é‡ç†è®ºå¤§å°: {vector_size_mb:.1f} MB")
print(f"ğŸ“Š å®é™…å†…å­˜å¢é•¿: {mem_after - mem_before:.1f} MB")

# å¯¼å…¥åˆ°ChromaDB
try:
    client.delete_collection(name="memory_test")
except:
    pass

collection = client.create_collection(name="memory_test")

print(f"\nğŸ’¾ å¯¼å…¥å‰å†…å­˜: {process.memory_info().rss / 1024 / 1024:.1f} MB")

# æ‰¹é‡å¯¼å…¥
batch_size = 100
for i in range(0, large_num, batch_size):
    end_idx = min(i + batch_size, large_num)
    collection.add(
        embeddings=large_embeddings[i:end_idx].tolist(),
        documents=large_docs[i:end_idx],
        ids=[f"doc_{j}" for j in range(i, end_idx)]
    )

gc.collect()
mem_final = process.memory_info().rss / 1024 / 1024

print(f"ğŸ’¾ å¯¼å…¥åå†…å­˜: {mem_final:.1f} MB")
print(f"ğŸ“ˆ ChromaDBé¢å¤–å ç”¨: {mem_final - mem_after:.1f} MB")

# ============================================================
# ç¬¬å››éƒ¨åˆ†ï¼šå‘é‡åŒ–æ€§èƒ½ä¼˜åŒ–
# ============================================================

print("\nã€ç¬¬å››éƒ¨åˆ†ï¼šå‘é‡åŒ–æ€§èƒ½ä¼˜åŒ–ã€‘")
print("-" * 60)

# æµ‹è¯•ä¸åŒbatch_sizeå¯¹å‘é‡åŒ–é€Ÿåº¦çš„å½±å“
num_texts = 100
test_texts = [f"æµ‹è¯•æ–‡æœ¬{i}ï¼Œå…³äºäº¤é€šå®‰å…¨å’Œæ³•è§„" for i in range(num_texts)]

batch_sizes = [1, 8, 16, 32, 64]

print(f"\nâ±ï¸  æµ‹è¯•ä¸åŒbatch_sizeçš„å‘é‡åŒ–é€Ÿåº¦:")
print("-" * 60)

for batch_size in batch_sizes:
    start = time.time()
    embeddings = model.encode(test_texts, batch_size=batch_size, show_progress_bar=False)
    end = time.time()
    
    elapsed = (end - start) * 1000
    texts_per_sec = num_texts / (elapsed / 1000)
    
    print(f"   batch_size {batch_size:2d}: {elapsed:6.2f}ms ({texts_per_sec:.1f} texts/s)")

print("\nğŸ’¡ å»ºè®®:")
print("   â€¢ CPU: batch_size=16-32")
print("   â€¢ GPU: batch_size=64-128")
print("   â€¢ æ ¹æ®å†…å­˜å¤§å°è°ƒæ•´")

# ============================================================
# ç¬¬äº”éƒ¨åˆ†ï¼šæŒä¹…åŒ– vs å†…å­˜æ¨¡å¼
# ============================================================

print("\nã€ç¬¬äº”éƒ¨åˆ†ï¼šæŒä¹…åŒ– vs å†…å­˜æ¨¡å¼ã€‘")
print("-" * 60)

# æµ‹è¯•æ•°æ®
test_num = 50
test_data_docs = [f"æ–‡æ¡£{i}" for i in range(test_num)]
test_data_embeddings = model.encode(test_data_docs, show_progress_bar=False)

# æµ‹è¯•1ï¼šæŒä¹…åŒ–æ¨¡å¼
print(f"\nâ±ï¸  æŒä¹…åŒ–æ¨¡å¼:")
persistent_client = chromadb.PersistentClient(path="./data/chroma_persistent_test")
try:
    persistent_client.delete_collection(name="test")
except:
    pass

start = time.time()
persistent_collection = persistent_client.create_collection(name="test")
persistent_collection.add(
    embeddings=test_data_embeddings.tolist(),
    documents=test_data_docs,
    ids=[f"doc_{i}" for i in range(test_num)]
)
persistent_time = (time.time() - start) * 1000

print(f"   å¯¼å…¥æ—¶é—´: {persistent_time:.2f}ms")

# æµ‹è¯•2ï¼šå†…å­˜æ¨¡å¼
print(f"\nâ±ï¸  å†…å­˜æ¨¡å¼:")
memory_client = chromadb.Client()

start = time.time()
memory_collection = memory_client.create_collection(name="test")
memory_collection.add(
    embeddings=test_data_embeddings.tolist(),
    documents=test_data_docs,
    ids=[f"doc_{i}" for i in range(test_num)]
)
memory_time = (time.time() - start) * 1000

print(f"   å¯¼å…¥æ—¶é—´: {memory_time:.2f}ms")

# å¯¹æ¯”
print(f"\nğŸ“Š æ€§èƒ½å¯¹æ¯”:")
print(f"   å†…å­˜æ¨¡å¼: {memory_time:.2f}ms")
print(f"   æŒä¹…åŒ–æ¨¡å¼: {persistent_time:.2f}ms")
print(f"   é€Ÿåº¦å·®å¼‚: {persistent_time/memory_time:.2f}x")

print(f"\nğŸ’¡ é€‰æ‹©å»ºè®®:")
print(f"   â€¢ å¼€å‘æµ‹è¯•: ç”¨å†…å­˜æ¨¡å¼ï¼ˆå¿«é€Ÿï¼‰")
print(f"   â€¢ ç”Ÿäº§ç¯å¢ƒ: ç”¨æŒä¹…åŒ–æ¨¡å¼ï¼ˆå¯é ï¼‰")

# ============================================================
# ç¬¬å…­éƒ¨åˆ†ï¼šä¼˜åŒ–å»ºè®®æ€»ç»“
# ============================================================

print("\nã€ç¬¬å…­éƒ¨åˆ†ï¼šä¼˜åŒ–å»ºè®®æ€»ç»“ã€‘")
print("=" * 60)

print("\nâœ… å¯¼å…¥ä¼˜åŒ–:")
print("   1. ä½¿ç”¨æ‰¹é‡å¯¼å…¥ï¼ˆbatch_size=50-100ï¼‰")
print("   2. é¢„å…ˆç”Ÿæˆæ‰€æœ‰å‘é‡ï¼Œç„¶åä¸€æ¬¡æ€§å¯¼å…¥")
print("   3. é¿å…é¢‘ç¹çš„å°æ‰¹é‡æ·»åŠ ")

print("\nâœ… æ£€ç´¢ä¼˜åŒ–:")
print("   1. åˆç†è®¾ç½®Top-Kï¼ˆé€šå¸¸5-10å°±å¤Ÿï¼‰")
print("   2. ä½¿ç”¨å…ƒæ•°æ®è¿‡æ»¤ç¼©å°èŒƒå›´")
print("   3. æ‰¹é‡æ£€ç´¢å¤šä¸ªé—®é¢˜")

print("\nâœ… å‘é‡åŒ–ä¼˜åŒ–:")
print("   1. ä½¿ç”¨åˆé€‚çš„batch_sizeï¼ˆ16-64ï¼‰")
print("   2. å¦‚æœæœ‰GPUï¼Œå¼€å¯GPUåŠ é€Ÿ")
print("   3. ç¼“å­˜å¸¸ç”¨æ–‡æœ¬çš„å‘é‡")

print("\nâœ… å†…å­˜ä¼˜åŒ–:")
print("   1. åŠæ—¶é‡Šæ”¾ä¸ç”¨çš„å‘é‡ï¼ˆdel, gc.collect()ï¼‰")
print("   2. å¤§è§„æ¨¡æ•°æ®åˆ†æ‰¹å¤„ç†")
print("   3. ä½¿ç”¨float16å‡å°‘å†…å­˜ï¼ˆå¦‚æœç²¾åº¦å…è®¸ï¼‰")

print("\nâœ… æ•°æ®åº“é€‰æ‹©:")
print("   â€¢ < 10ä¸‡å‘é‡: ChromaDB âœ…")
print("   â€¢ 10ä¸‡-100ä¸‡: ChromaDB å¯ä»¥")
print("   â€¢ > 100ä¸‡: è€ƒè™‘Milvus/Qdrant")

# ============================================================
# æ¸…ç†
# ============================================================

print("\nã€æ¸…ç†æµ‹è¯•æ•°æ®ã€‘")
print("-" * 60)

# åˆ é™¤æµ‹è¯•é›†åˆ
test_collections = ["memory_test", "test"]
for coll_name in test_collections:
    try:
        client.delete_collection(name=coll_name)
        print(f"ğŸ—‘ï¸  åˆ é™¤é›†åˆ: {coll_name}")
    except:
        pass

# åˆ é™¤æ‰¹é‡æµ‹è¯•é›†åˆ
for batch_size in batch_sizes:
    try:
        client.delete_collection(name=f"test_batch_{batch_size}")
        print(f"ğŸ—‘ï¸  åˆ é™¤é›†åˆ: test_batch_{batch_size}")
    except:
        pass

print("\nâœ… æ¸…ç†å®Œæˆ")

# ============================================================
# æ€»ç»“
# ============================================================

print("\n" + "=" * 60)
print("ğŸ‰ æ€§èƒ½ä¼˜åŒ–å­¦ä¹ å®Œæˆï¼")
print("=" * 60)

print("\nâœ… æŒæ¡çš„çŸ¥è¯†:")
print("   1. æ‰¹é‡å¯¼å…¥æ€§èƒ½æµ‹è¯•")
print("   2. æ£€ç´¢æ€§èƒ½åˆ†æ")
print("   3. å†…å­˜ä½¿ç”¨ä¼˜åŒ–")
print("   4. å‘é‡åŒ–é€Ÿåº¦ä¼˜åŒ–")
print("   5. æŒä¹…åŒ– vs å†…å­˜æ¨¡å¼å¯¹æ¯”")

print("\nğŸ“ Step 4 å®Œæˆï¼")
print("   ä½ å·²ç»æŒæ¡äº†ChromaDBçš„:")
print("   â€¢ åŸºç¡€æ“ä½œï¼ˆå¢åˆ æ”¹æŸ¥ï¼‰")
print("   â€¢ é«˜çº§æ£€ç´¢ï¼ˆè¿‡æ»¤ã€æ’åºï¼‰")
print("   â€¢ æ€§èƒ½ä¼˜åŒ–ï¼ˆæ‰¹é‡ã€å†…å­˜ï¼‰")

print("\nğŸ¯ ä¸‹ä¸€æ­¥:")
print("   è¿›å…¥ Step 5: æ£€ç´¢ä¸ç”Ÿæˆï¼ˆRAGå®Œæ•´æµç¨‹ï¼‰")
print("   cd ../step5_retrieval")
print("   cat README.md")

print("\n" + "=" * 60)

