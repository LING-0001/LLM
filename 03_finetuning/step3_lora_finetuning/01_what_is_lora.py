#!/usr/bin/env python3
"""
LoRA åŸç†è®²è§£

é€šè¿‡å¯è§†åŒ–å’Œç¤ºä¾‹ç†è§£LoRAçš„å·¥ä½œåŸç†
"""

import numpy as np


def explain_traditional_finetuning():
    """è§£é‡Šä¼ ç»Ÿå¾®è°ƒ"""
    print("=" * 60)
    print("ä¼ ç»Ÿå¾®è°ƒ vs LoRA".center(60))
    print("=" * 60)
    
    print("\nã€ä¼ ç»Ÿå…¨é‡å¾®è°ƒã€‘")
    print("-" * 60)
    print()
    print("åŸç†: æ›´æ–°æ¨¡å‹çš„æ‰€æœ‰å‚æ•°")
    print()
    print("ç¤ºä¾‹: å‡è®¾æ¨¡å‹æœ‰3B(30äº¿)ä¸ªå‚æ•°")
    print()
    print("  åŸå§‹æ¨¡å‹:  Wâ‚, Wâ‚‚, Wâ‚ƒ, ..., Wâ‚ƒâ‚€â‚€â‚€â‚€â‚€â‚€â‚€â‚€â‚€")
    print("             â†“è®­ç»ƒåå…¨éƒ¨æ›´æ–°")
    print("  å¾®è°ƒå:    Wâ‚', Wâ‚‚', Wâ‚ƒ', ..., Wâ‚ƒâ‚€â‚€â‚€â‚€â‚€â‚€â‚€â‚€â‚€'")
    print()
    print("éœ€è¦:")
    print("  ğŸ’¾ å†…å­˜: ~24GB+ (å­˜å‚¨æ¢¯åº¦å’Œä¼˜åŒ–å™¨çŠ¶æ€)")
    print("  â±ï¸  æ—¶é—´: æ•°å°æ—¶")
    print("  ğŸ’° æˆæœ¬: éœ€è¦é«˜ç«¯GPU")
    print()
    print("ä¼˜ç‚¹:")
    print("  âœ… æ•ˆæœæœ€å¥½")
    print()
    print("ç¼ºç‚¹:")
    print("  âŒ èµ„æºéœ€æ±‚æé«˜")
    print("  âŒ è®­ç»ƒæ—¶é—´é•¿")


def explain_lora():
    """è§£é‡ŠLoRA"""
    print("\nã€LoRA (Low-Rank Adaptation)ã€‘")
    print("-" * 60)
    print()
    print("åŸç†: å†»ç»“åŸå§‹å‚æ•°ï¼Œåªè®­ç»ƒå°çš„é€‚é…çŸ©é˜µ")
    print()
    print("ç¤ºä¾‹: åŒæ ·3Bå‚æ•°çš„æ¨¡å‹")
    print()
    print("  åŸå§‹æ¨¡å‹:  Wâ‚, Wâ‚‚, Wâ‚ƒ, ..., Wâ‚ƒâ‚€â‚€â‚€â‚€â‚€â‚€â‚€â‚€â‚€  (å†»ç»“ â„ï¸)")
    print("             +")
    print("  LoRAå±‚:    Aâ‚Ã—Bâ‚, Aâ‚‚Ã—Bâ‚‚, ...           (è®­ç»ƒ ğŸ”¥)")
    print("             â†“")
    print("  è¾“å‡º:      Wâ‚+Aâ‚Ã—Bâ‚, Wâ‚‚+Aâ‚‚Ã—Bâ‚‚, ...")
    print()
    print("LoRAå‚æ•°é‡: ä»…å‡ ç™¾ä¸‡ä¸ª (0.1% of 3B)")
    print()
    print("éœ€è¦:")
    print("  ğŸ’¾ å†…å­˜: ~4-8GB")
    print("  â±ï¸  æ—¶é—´: å‡ ååˆ†é’Ÿ")
    print("  ğŸ’° æˆæœ¬: æ™®é€šGPUç”šè‡³CPUå¯è¡Œ")
    print()
    print("ä¼˜ç‚¹:")
    print("  âœ… èµ„æºéœ€æ±‚ä½")
    print("  âœ… è®­ç»ƒé€Ÿåº¦å¿«")
    print("  âœ… æ•ˆæœæ¥è¿‘å…¨é‡å¾®è°ƒ (90-95%)")
    print()
    print("ç¼ºç‚¹:")
    print("  âš ï¸  æ•ˆæœç•¥é€Šäºå…¨é‡å¾®è°ƒ")


def visualize_lora_math():
    """ç”¨æ•°å­¦ç¤ºä¾‹å±•ç¤ºLoRA"""
    print("\n" + "=" * 60)
    print("LoRA æ•°å­¦åŸç†".center(60))
    print("=" * 60)
    
    print("\nå‡è®¾åŸå§‹æƒé‡çŸ©é˜µ W æ˜¯ 4Ã—4:")
    W = np.array([
        [1.2, 0.5, 0.8, 0.3],
        [0.7, 1.1, 0.4, 0.9],
        [0.6, 0.3, 1.3, 0.7],
        [0.9, 0.8, 0.5, 1.0]
    ])
    print(W)
    print(f"å‚æ•°é‡: {W.size}")
    
    print("\nLoRA ä½¿ç”¨ä¸¤ä¸ªå°çŸ©é˜µ A(4Ã—2) å’Œ B(2Ã—4):")
    print("rank = 2 (è¿œå°äº4)")
    
    A = np.array([
        [0.1, 0.2],
        [0.3, 0.1],
        [0.2, 0.3],
        [0.1, 0.2]
    ])
    
    B = np.array([
        [0.2, 0.1, 0.3, 0.2],
        [0.1, 0.2, 0.1, 0.3]
    ])
    
    print("\nA (4Ã—2):")
    print(A)
    print(f"å‚æ•°é‡: {A.size}")
    
    print("\nB (2Ã—4):")
    print(B)
    print(f"å‚æ•°é‡: {B.size}")
    
    print(f"\nLoRA æ€»å‚æ•°: {A.size + B.size} (vs åŸå§‹ {W.size})")
    print(f"å‚æ•°å‡å°‘: {(1 - (A.size + B.size) / W.size) * 100:.0f}%")
    
    print("\nA Ã— B çš„ç»“æœ (4Ã—4):")
    AB = A @ B
    print(AB)
    
    print("\næœ€ç»ˆæƒé‡ = W + AÃ—B:")
    W_new = W + AB
    print(W_new)
    
    print("\nâœ¨ å…³é”®ç‚¹:")
    print("  - åªè®­ç»ƒ A å’Œ B (16ä¸ªå‚æ•°)")
    print("  - åŸå§‹ W ä¿æŒä¸å˜ (16ä¸ªå‚æ•°)")
    print("  - èŠ‚çœäº†å¤§é‡å†…å­˜å’Œè®¡ç®—")


def explain_lora_params():
    """è§£é‡ŠLoRAå‚æ•°"""
    print("\n" + "=" * 60)
    print("LoRA å…³é”®å‚æ•°".center(60))
    print("=" * 60)
    
    params = [
        {
            "name": "rank (r)",
            "desc": "LoRAçŸ©é˜µçš„ç§©ï¼Œå†³å®šé€‚é…èƒ½åŠ›",
            "range": "4-64",
            "recommend": "8-16",
            "effect": "è¶Šå¤§æ•ˆæœè¶Šå¥½ï¼Œä½†å†…å­˜å’Œæ—¶é—´æˆæœ¬è¶Šé«˜"
        },
        {
            "name": "alpha",
            "desc": "ç¼©æ”¾å› å­ï¼Œæ§åˆ¶LoRAçš„å½±å“ç¨‹åº¦",
            "range": "8-64",
            "recommend": "16-32 (é€šå¸¸æ˜¯rankçš„2å€)",
            "effect": "å½±å“å­¦ä¹ å¼ºåº¦"
        },
        {
            "name": "target_modules",
            "desc": "åº”ç”¨LoRAçš„æ¨¡å—",
            "range": "['q_proj', 'v_proj'] æˆ– ['q_proj', 'k_proj', 'v_proj', 'o_proj']",
            "recommend": "['q_proj', 'v_proj']",
            "effect": "æ›´å¤šæ¨¡å—=æ›´å¼ºä½†æ›´æ…¢"
        },
        {
            "name": "dropout",
            "desc": "é˜²æ­¢è¿‡æ‹Ÿåˆ",
            "range": "0-0.1",
            "recommend": "0.05",
            "effect": "å°æ•°æ®é›†å»ºè®®ä½¿ç”¨"
        }
    ]
    
    print()
    for p in params:
        print(f"ğŸ“Œ {p['name']}")
        print(f"   è¯´æ˜: {p['desc']}")
        print(f"   èŒƒå›´: {p['range']}")
        print(f"   æ¨è: {p['recommend']}")
        print(f"   å½±å“: {p['effect']}")
        print()


def show_comparison_table():
    """å±•ç¤ºå¯¹æ¯”è¡¨"""
    print("\n" + "=" * 60)
    print("ğŸ“Š å…¨é‡å¾®è°ƒ vs LoRA å¯¹æ¯”".center(60))
    print("=" * 60)
    
    print()
    print("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print("â”‚   ç»´åº¦      â”‚   å…¨é‡å¾®è°ƒ      â”‚      LoRA       â”‚")
    print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
    print("â”‚ è®­ç»ƒå‚æ•°    â”‚ 100%            â”‚ 0.1-1%          â”‚")
    print("â”‚ å†…å­˜éœ€æ±‚    â”‚ 24GB+           â”‚ 4-8GB           â”‚")
    print("â”‚ è®­ç»ƒæ—¶é—´    â”‚ æ•°å°æ—¶          â”‚ å‡ ååˆ†é’Ÿ        â”‚")
    print("â”‚ æ•ˆæœ        â”‚ 100% (åŸºå‡†)     â”‚ 90-95%          â”‚")
    print("â”‚ é€‚ç”¨åœºæ™¯    â”‚ å¤§é‡æ•°æ®        â”‚ å°æ•°æ®+ä½èµ„æº   â”‚")
    print("â”‚ æ¨¡å‹å¤§å°    â”‚ å®Œæ•´æ¨¡å‹        â”‚ åŸºç¡€æ¨¡å‹+é€‚é…å™¨ â”‚")
    print("â”‚ åˆ‡æ¢æˆæœ¬    â”‚ éœ€é‡æ–°åŠ è½½      â”‚ ç§’çº§åˆ‡æ¢        â”‚")
    print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")


def show_use_cases():
    """å±•ç¤ºåº”ç”¨åœºæ™¯"""
    print("\n" + "=" * 60)
    print("ğŸ¯ ä»€ä¹ˆæ—¶å€™ç”¨LoRA".center(60))
    print("=" * 60)
    
    print()
    print("âœ… é€‚åˆç”¨LoRA:")
    print("  - èµ„æºæœ‰é™ï¼ˆæ™®é€šç¬”è®°æœ¬ã€å°GPUï¼‰")
    print("  - æ•°æ®é‡å°åˆ°ä¸­ç­‰ï¼ˆ100-10000æ¡ï¼‰")
    print("  - éœ€è¦å¿«é€Ÿå®éªŒå¤šä¸ªç‰ˆæœ¬")
    print("  - éœ€è¦åŒæ—¶ç»´æŠ¤å¤šä¸ªå¾®è°ƒç‰ˆæœ¬")
    print()
    
    print("âŒ ä¸é€‚åˆç”¨LoRA:")
    print("  - æœ‰å……è¶³èµ„æºï¼ˆå¤§GPUé›†ç¾¤ï¼‰")
    print("  - å¤§è§„æ¨¡æ•°æ®ï¼ˆç™¾ä¸‡çº§ï¼‰")
    print("  - è¿½æ±‚æè‡´æ•ˆæœ")
    print("  - éœ€è¦æ”¹å˜æ¨¡å‹æ¶æ„")


def show_our_plan():
    """å±•ç¤ºæˆ‘ä»¬çš„æ–¹æ¡ˆ"""
    print("\n" + "=" * 60)
    print("ğŸš€ æˆ‘ä»¬çš„å¾®è°ƒæ–¹æ¡ˆ".center(60))
    print("=" * 60)
    
    print()
    print("æ¨¡å‹: Qwen2.5-1.5B")
    print("  - å‚æ•°é‡: 1.5B")
    print("  - å·²ä¸‹è½½: âœ…")
    print()
    
    print("LoRAé…ç½®:")
    print("  - rank: 8")
    print("  - alpha: 16")
    print("  - target: ['q_proj', 'v_proj']")
    print("  - å¯è®­ç»ƒå‚æ•°: ~400ä¸‡ (0.27% of 1.5B)")
    print()
    
    print("è®­ç»ƒé…ç½®:")
    print("  - æ•°æ®: 31æ¡è®­ç»ƒ + 5æ¡éªŒè¯")
    print("  - epochs: 10")
    print("  - batch_size: 1")
    print("  - learning_rate: 2e-4")
    print("  - è®¾å¤‡: CPU (Apple M1)")
    print()
    
    print("é¢„æœŸ:")
    print("  - è®­ç»ƒæ—¶é—´: 30-60åˆ†é’Ÿ")
    print("  - å†…å­˜ä½¿ç”¨: ~4GB")
    print("  - æ¨¡å‹å¤§å°: ~3GB (åŸºç¡€) + ~15MB (LoRA)")


def show_next_steps():
    """æ˜¾ç¤ºä¸‹ä¸€æ­¥"""
    print("\n" + "=" * 60)
    print("ğŸ“ æ€»ç»“".center(60))
    print("=" * 60)
    
    print()
    print("ä½ ç°åœ¨åº”è¯¥ç†è§£äº†:")
    print("  âœ… LoRAé€šè¿‡å°çŸ©é˜µé€‚é…å®ç°ä½æˆæœ¬å¾®è°ƒ")
    print("  âœ… rankå’Œalphaæ˜¯å…³é”®å‚æ•°")
    print("  âœ… LoRAæ•ˆæœæ¥è¿‘å…¨é‡å¾®è°ƒä½†èµ„æºéœ€æ±‚ä½å¾ˆå¤š")
    print("  âœ… é€‚åˆèµ„æºæœ‰é™çš„ä¸ªäººå’Œå°å›¢é˜Ÿ")
    print()
    
    print("ğŸš€ ä¸‹ä¸€æ­¥:")
    print("  python 02_simple_finetune.py  # å¼€å§‹çœŸæ­£çš„å¾®è°ƒï¼")


def main():
    """ä¸»å‡½æ•°"""
    explain_traditional_finetuning()
    input("\næŒ‰ Enter ç»§ç»­...")
    
    explain_lora()
    input("\næŒ‰ Enter ç»§ç»­...")
    
    visualize_lora_math()
    input("\næŒ‰ Enter ç»§ç»­...")
    
    explain_lora_params()
    input("\næŒ‰ Enter ç»§ç»­...")
    
    show_comparison_table()
    input("\næŒ‰ Enter ç»§ç»­...")
    
    show_use_cases()
    input("\næŒ‰ Enter ç»§ç»­...")
    
    show_our_plan()
    input("\næŒ‰ Enter ç»§ç»­...")
    
    show_next_steps()


if __name__ == "__main__":
    try:
        main()
    except (KeyboardInterrupt, EOFError):
        print("\n\nâœ… LoRAåŸç†è®²è§£å®Œæˆ")
        print("ğŸš€ ä¸‹ä¸€æ­¥: python 02_simple_finetune.py")

